<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="text/html; charset=utf-8" http-equiv="Content-Type">
<title>Explain - BINN</title>
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<meta name="generator" content="mkdocs-1.5.3, mkdocs-gitbook-1.0.7">

<link rel="shortcut icon" href="../../images/favicon.ico" type="image/x-icon">
<meta name="HandheldFriendly" content="true"/>
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black">
<meta rel="next" href="" />
<link href="../../css/style.min.css" rel="stylesheet">
<link href="../../assets/_mkdocstrings.css" rel="stylesheet"> 
</head>

<body>
<div class="book">
<div class="book-summary">

<nav role="navigation">
<ul class="summary">
<li>
<a href="../.." target="_blank" class="custom-link">BINN</a>
</li>
<li class="divider"></li>
<li class="chapter" data-path="">
<a href="../..">Home</a>
<li class="header">Examples & tutorials</li>

<li>
<a href="../../binn_example/" class="">BINN - Biologically Informed Neural Network</a>
</li>

<li>
<a href="../../shap_example/" class="">Shap example</a>
</li>

<li>
<a href="../../sklearn_api/" class="">Scikit-learn API</a>
</li>

<li>
<a href="../../robustness/" class="">Robustness</a>
</li>

<li class="header">API Reference</li>

<li>
<a href="../binn_ref/" class="">BINN</a>
</li>

<li>
<a href="../net_ref/" class="">Network</a>
</li>

<li>
<a href="./" class="active">Explain</a>
</li>

<li>
<a href="../import_ref/" class="">Importance Network & Visualization</a>
</li>

<li>
<a href="../sk_ref/" class="">Scikit-learn API</a>
</li>

<li class="divider"></li>



<li><a href="http://www.mkdocs.org">
Published with MkDocs
</a></li>

<li><a href="https://github.com/GitbookIO/theme-default">
Theme by GitBook
</a></li>
</ul>

</nav>

</div> <!-- end of book-summary -->

<div class="book-body">
<div class="body-inner">
<div class="book-header" role="navigation">

<!-- Title -->
<h1>
<i class="fa fa-circle-o-notch fa-spin"></i>
<a href="." ></a>
</h1>

</div> <!-- end of book-header -->

<div class="page-wrapper" tabindex="-1" role="main">
<div class="page-inner">

<section class="normal markdown-section">



<h1 id="explain">Explain</h1>


<div class="doc doc-object doc-module">



<a id="binn.explainer"></a>
  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">




<h2 id="binn.explainer.BINNExplainer" class="doc doc-heading">
          <code>BINNExplainer</code>


</h2>


  <div class="doc doc-contents ">

  
      <p>A class for explaining the predictions of a BINN model using SHAP values.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>model</code></td>
          <td>
                <code><a class="autorefs autorefs-internal" title="binn.BINN" href="../binn_ref/#binn.binn.BINN">BINN</a></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>A trained BINN model.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

            <details class="quote">
              <summary>Source code in <code>binn/explainer.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 10</span>
<span class="normal"> 11</span>
<span class="normal"> 12</span>
<span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BINNExplainer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class for explaining the predictions of a BINN model using SHAP values.</span>

<span class="sd">    Args:</span>
<span class="sd">        model (BINN): A trained BINN model.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">BINN</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

    <span class="k">def</span> <span class="nf">update_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">BINN</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

    <span class="k">def</span> <span class="nf">explain</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">background_data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates SHAP explanations for a given test_data by computing the Shapley values for each feature using</span>
<span class="sd">        the provided background_data. The feature importances are then aggregated and returned in a pandas dataframe.</span>

<span class="sd">        Args:</span>
<span class="sd">            test_data (torch.Tensor): The input data for which to generate the explanations.</span>
<span class="sd">            background_data (torch.Tensor): The background data to use for computing the Shapley values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            pd.DataFrame: A dataframe containing the aggregated SHAP feature importances.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">shap_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_explain_layers</span><span class="p">(</span><span class="n">background_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">)</span>
        <span class="n">feature_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;target&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;source name&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;target name&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;value&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;source layer&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;target layer&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="p">}</span>
        <span class="n">connectivity_matrices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_connectivity_matrices</span><span class="p">()</span>
        <span class="n">feature_id_mapping</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="n">feature_id</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">feature_id_mapping</span><span class="p">[</span><span class="s2">&quot;root&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">feature_id</span>
        <span class="k">for</span> <span class="n">layer_features</span> <span class="ow">in</span> <span class="n">shap_dict</span><span class="p">[</span><span class="s2">&quot;features&quot;</span><span class="p">]:</span>
            <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">layer_features</span><span class="p">:</span>
                <span class="n">feature_id</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">feature_id_mapping</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="n">feature_id</span>

        <span class="n">curr_layer</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">sv</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">cm</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
            <span class="n">shap_dict</span><span class="p">[</span><span class="s2">&quot;shap_values&quot;</span><span class="p">],</span> <span class="n">shap_dict</span><span class="p">[</span><span class="s2">&quot;features&quot;</span><span class="p">],</span> <span class="n">connectivity_matrices</span>
        <span class="p">):</span>
            <span class="n">sv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">sv</span><span class="p">)</span>
            <span class="n">sv</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">sv</span><span class="p">)</span>
            <span class="n">sv_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sv</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sv_mean</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
                <span class="n">n_classes</span> <span class="o">=</span> <span class="n">sv_mean</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">connections</span> <span class="o">=</span> <span class="n">cm</span><span class="p">[</span><span class="n">cm</span><span class="o">.</span><span class="n">index</span> <span class="o">==</span> <span class="n">features</span><span class="p">[</span><span class="n">feature</span><span class="p">]]</span>
                <span class="n">connections</span> <span class="o">=</span> <span class="n">connections</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span>
                    <span class="p">:,</span> <span class="p">(</span><span class="n">connections</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="p">]</span>  <span class="c1"># get targets and append to target</span>
                <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">connections</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">curr_class</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_classes</span><span class="p">):</span>
                        <span class="n">feature_dict</span><span class="p">[</span><span class="s2">&quot;source&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                            <span class="n">feature_id_mapping</span><span class="p">[</span><span class="n">features</span><span class="p">[</span><span class="n">feature</span><span class="p">]]</span>
                        <span class="p">)</span>
                        <span class="n">feature_dict</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">feature_id_mapping</span><span class="p">[</span><span class="n">target</span><span class="p">])</span>
                        <span class="n">feature_dict</span><span class="p">[</span><span class="s2">&quot;source name&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="n">feature</span><span class="p">])</span>
                        <span class="n">feature_dict</span><span class="p">[</span><span class="s2">&quot;target name&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
                        <span class="n">feature_dict</span><span class="p">[</span><span class="s2">&quot;value&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sv_mean</span><span class="p">[</span><span class="n">curr_class</span><span class="p">][</span><span class="n">feature</span><span class="p">])</span>
                        <span class="n">feature_dict</span><span class="p">[</span><span class="s2">&quot;type&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_class</span><span class="p">)</span>
                        <span class="n">feature_dict</span><span class="p">[</span><span class="s2">&quot;source layer&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_layer</span><span class="p">)</span>
                        <span class="n">feature_dict</span><span class="p">[</span><span class="s2">&quot;target layer&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_layer</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">curr_layer</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">feature_dict</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">df</span>

    <span class="k">def</span> <span class="nf">fast_train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span> 
            <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">total_accuracy</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">)</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">total_accuracy</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">targets</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span>

            <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
            <span class="n">avg_accuracy</span> <span class="o">=</span> <span class="n">total_accuracy</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Final epoch: Average Accuracy </span><span class="si">{</span><span class="n">avg_accuracy</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">, Average Loss: </span><span class="si">{</span><span class="n">avg_loss</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span>

    <span class="k">def</span> <span class="nf">explain_average</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">test_data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">background_data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">nr_iterations</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">max_epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">dataloader</span><span class="p">,</span>
        <span class="n">fast_train</span> <span class="p">:</span> <span class="nb">bool</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the SHAP explanations for the given test_data by averaging the Shapley values over multiple iterations.</span>
<span class="sd">        For each iteration, the model&#39;s parameters are randomly initialized and trained on the provided data using</span>
<span class="sd">        the provided trainer and dataloader. The feature importances are then aggregated and returned in a pandas dataframe.</span>

<span class="sd">        Args:</span>
<span class="sd">            test_data (torch.Tensor): The input data for which to generate the explanations.</span>
<span class="sd">            background_data (torch.Tensor): The background data to use for computing the Shapley values.</span>
<span class="sd">            nr_iterations (int): The number of iterations to use for averaging the Shapley values.</span>
<span class="sd">            trainer: The PyTorch Lightning trainer to use for training the model.</span>
<span class="sd">            dataloader: The PyTorch DataLoader to use for loading the data.</span>

<span class="sd">        Returns:</span>
<span class="sd">            pd.DataFrame: A dataframe containing the aggregated SHAP feature importances.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dfs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nr_iterations</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iteration </span><span class="si">{</span><span class="n">iteration</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">reset_params</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">fast_train</span><span class="p">:</span>
                <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">configure_optimizers</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fast_train</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">max_epochs</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="n">max_epochs</span><span class="p">)</span>
                <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">)</span>
            <span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">explain</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">background_data</span><span class="p">)</span>
            <span class="n">dfs</span><span class="p">[</span><span class="n">iteration</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span>

        <span class="n">col_names</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;value_</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">dfs</span><span class="o">.</span><span class="n">keys</span><span class="p">())))]</span>
        <span class="n">values</span> <span class="o">=</span> <span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">values</span> <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">dfs</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
        <span class="n">values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
        <span class="n">values_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">values_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">dfs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;value&quot;</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">df</span><span class="p">[</span><span class="n">col_names</span><span class="p">]</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">T</span>
        <span class="n">df</span><span class="p">[</span><span class="s2">&quot;value_mean&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">values_mean</span>
        <span class="n">df</span><span class="p">[</span><span class="s2">&quot;values_std&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">values_std</span>
        <span class="n">df</span><span class="p">[</span><span class="s2">&quot;value&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">values_mean</span>
        <span class="k">return</span> <span class="n">df</span>

    <span class="k">def</span> <span class="nf">recursive_pathway_elimination</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_data</span><span class="p">,</span>
        <span class="n">design_matrix</span><span class="p">,</span>
        <span class="n">nr_iterations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
        <span class="n">max_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
        <span class="n">clip_threshold</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
        <span class="n">constant_removal_rate</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
        <span class="n">min_features_per_layer</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">early_stopping</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">rpe</span> <span class="o">=</span> <span class="n">RecursivePathwayElimination</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>
        <span class="n">return_dict</span> <span class="o">=</span> <span class="n">rpe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
            <span class="n">input_data</span><span class="o">=</span><span class="n">input_data</span><span class="p">,</span>
            <span class="n">design_matrix</span><span class="o">=</span><span class="n">design_matrix</span><span class="p">,</span>
            <span class="n">nr_iterations</span><span class="o">=</span><span class="n">nr_iterations</span><span class="p">,</span>
            <span class="n">max_epochs</span><span class="o">=</span><span class="n">max_epochs</span><span class="p">,</span>
            <span class="n">clip_threshold</span><span class="o">=</span><span class="n">clip_threshold</span><span class="p">,</span>
            <span class="n">constant_removal_rate</span><span class="o">=</span><span class="n">constant_removal_rate</span><span class="p">,</span>
            <span class="n">min_features_per_layer</span><span class="o">=</span><span class="n">min_features_per_layer</span><span class="p">,</span>
            <span class="n">early_stopping</span><span class="o">=</span><span class="n">early_stopping</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rpe_model</span> <span class="o">=</span> <span class="n">rpe</span><span class="o">.</span><span class="n">get_final_model</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rpe_data</span> <span class="o">=</span> <span class="n">rpe</span><span class="o">.</span><span class="n">get_final_data</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">return_dict</span>

    <span class="k">def</span> <span class="nf">explain_input</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">test_data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">background_data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the SHAP explanations for the given test_data for a specific layer in the model by computing the</span>
<span class="sd">        Shapley values for each feature using the provided background_data. The feature importances are then returned</span>
<span class="sd">        in a dictionary.</span>

<span class="sd">        Args:</span>
<span class="sd">            test_data (torch.Tensor): The input data for which to generate the explanations.</span>
<span class="sd">            background_data (torch.Tensor): The background data to use for computing the Shapley values.</span>
<span class="sd">            layer (int): The index of the layer for which to compute the SHAP explanations.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict: A dictionary containing the SHAP feature importances.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">DeepExplainer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">background_data</span><span class="p">)</span>
        <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>

        <span class="n">shap_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;features&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layer_names</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;shap_values&quot;</span><span class="p">:</span> <span class="n">shap_values</span><span class="p">}</span>

        <span class="k">return</span> <span class="n">shap_dict</span>

    <span class="k">def</span> <span class="nf">_explain_layers</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">background_data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">test_data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Helper method to compute SHAP explanations for each layer in the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            background_data (torch.Tensor): The background data to use for computing the Shapley values.</span>
<span class="sd">            test_data (torch.Tensor): The input data for which to generate the explanations.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict: A dictionary containing the SHAP feature importances for each layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">feature_index</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">intermediate_data</span> <span class="o">=</span> <span class="n">test_data</span>

        <span class="n">shap_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;features&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;shap_values&quot;</span><span class="p">:</span> <span class="p">[]}</span>

        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
                <span class="s2">&quot;Residual&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">name</span> <span class="ow">or</span> <span class="s2">&quot;final&quot;</span> <span class="ow">in</span> <span class="n">name</span>
            <span class="p">):</span>
                <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">DeepExplainer</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">layer</span><span class="p">),</span> <span class="n">background_data</span><span class="p">)</span>
                <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
                <span class="n">shap_dict</span><span class="p">[</span><span class="s2">&quot;features&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layer_names</span><span class="p">[</span><span class="n">feature_index</span><span class="p">])</span>
                <span class="n">shap_dict</span><span class="p">[</span><span class="s2">&quot;shap_values&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">shap_values</span><span class="p">)</span>
                <span class="n">feature_index</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="n">intermediate_data</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">intermediate_data</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">)</span>
                <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">)</span>
                <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="n">intermediate_data</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">intermediate_data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">shap_dict</span>

    <span class="k">def</span> <span class="nf">_explain_layer</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">background_data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">test_data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">wanted_layer</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="n">intermediate_data</span> <span class="o">=</span> <span class="n">test_data</span>

        <span class="n">shap_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;features&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;shap_values&quot;</span><span class="p">:</span> <span class="p">[]}</span>
        <span class="n">layer_index</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
                <span class="s2">&quot;Residual&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">name</span> <span class="ow">or</span> <span class="s2">&quot;final&quot;</span> <span class="ow">in</span> <span class="n">name</span>
            <span class="p">):</span>
                <span class="k">if</span> <span class="n">layer_index</span> <span class="o">==</span> <span class="n">wanted_layer</span><span class="p">:</span>
                    <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">DeepExplainer</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">layer</span><span class="p">),</span> <span class="n">background_data</span><span class="p">)</span>
                    <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
                    <span class="n">shap_dict</span><span class="p">[</span><span class="s2">&quot;features&quot;</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layer_names</span><span class="p">[</span><span class="n">wanted_layer</span><span class="p">]</span>
                    <span class="n">shap_dict</span><span class="p">[</span><span class="s2">&quot;shap_values&quot;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">shap_values</span>
                    <span class="k">return</span> <span class="n">shap_dict</span>
                <span class="n">layer_index</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">intermediate_data</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">intermediate_data</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">)</span>
                <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">)</span>
                <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="n">intermediate_data</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">intermediate_data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">shap_dict</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">




<h3 id="binn.explainer.BINNExplainer.explain" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">explain</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">background_data</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Generates SHAP explanations for a given test_data by computing the Shapley values for each feature using
the provided background_data. The feature importances are then aggregated and returned in a pandas dataframe.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>test_data</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The input data for which to generate the explanations.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>background_data</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The background data to use for computing the Shapley values.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>



  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>pd.DataFrame: A dataframe containing the aggregated SHAP feature importances.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>binn/explainer.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">explain</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">background_data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generates SHAP explanations for a given test_data by computing the Shapley values for each feature using</span>
<span class="sd">    the provided background_data. The feature importances are then aggregated and returned in a pandas dataframe.</span>

<span class="sd">    Args:</span>
<span class="sd">        test_data (torch.Tensor): The input data for which to generate the explanations.</span>
<span class="sd">        background_data (torch.Tensor): The background data to use for computing the Shapley values.</span>

<span class="sd">    Returns:</span>
<span class="sd">        pd.DataFrame: A dataframe containing the aggregated SHAP feature importances.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">shap_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_explain_layers</span><span class="p">(</span><span class="n">background_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">)</span>
    <span class="n">feature_dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;source&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;target&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;source name&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;target name&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;value&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;source layer&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;target layer&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="p">}</span>
    <span class="n">connectivity_matrices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_connectivity_matrices</span><span class="p">()</span>
    <span class="n">feature_id_mapping</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="n">feature_id</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">feature_id_mapping</span><span class="p">[</span><span class="s2">&quot;root&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">feature_id</span>
    <span class="k">for</span> <span class="n">layer_features</span> <span class="ow">in</span> <span class="n">shap_dict</span><span class="p">[</span><span class="s2">&quot;features&quot;</span><span class="p">]:</span>
        <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">layer_features</span><span class="p">:</span>
            <span class="n">feature_id</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">feature_id_mapping</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">=</span> <span class="n">feature_id</span>

    <span class="n">curr_layer</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">sv</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">cm</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
        <span class="n">shap_dict</span><span class="p">[</span><span class="s2">&quot;shap_values&quot;</span><span class="p">],</span> <span class="n">shap_dict</span><span class="p">[</span><span class="s2">&quot;features&quot;</span><span class="p">],</span> <span class="n">connectivity_matrices</span>
    <span class="p">):</span>
        <span class="n">sv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">sv</span><span class="p">)</span>
        <span class="n">sv</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">sv</span><span class="p">)</span>
        <span class="n">sv_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sv</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sv_mean</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">n_classes</span> <span class="o">=</span> <span class="n">sv_mean</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">connections</span> <span class="o">=</span> <span class="n">cm</span><span class="p">[</span><span class="n">cm</span><span class="o">.</span><span class="n">index</span> <span class="o">==</span> <span class="n">features</span><span class="p">[</span><span class="n">feature</span><span class="p">]]</span>
            <span class="n">connections</span> <span class="o">=</span> <span class="n">connections</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span>
                <span class="p">:,</span> <span class="p">(</span><span class="n">connections</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="p">]</span>  <span class="c1"># get targets and append to target</span>
            <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">connections</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">curr_class</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_classes</span><span class="p">):</span>
                    <span class="n">feature_dict</span><span class="p">[</span><span class="s2">&quot;source&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="n">feature_id_mapping</span><span class="p">[</span><span class="n">features</span><span class="p">[</span><span class="n">feature</span><span class="p">]]</span>
                    <span class="p">)</span>
                    <span class="n">feature_dict</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">feature_id_mapping</span><span class="p">[</span><span class="n">target</span><span class="p">])</span>
                    <span class="n">feature_dict</span><span class="p">[</span><span class="s2">&quot;source name&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="n">feature</span><span class="p">])</span>
                    <span class="n">feature_dict</span><span class="p">[</span><span class="s2">&quot;target name&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
                    <span class="n">feature_dict</span><span class="p">[</span><span class="s2">&quot;value&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sv_mean</span><span class="p">[</span><span class="n">curr_class</span><span class="p">][</span><span class="n">feature</span><span class="p">])</span>
                    <span class="n">feature_dict</span><span class="p">[</span><span class="s2">&quot;type&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_class</span><span class="p">)</span>
                    <span class="n">feature_dict</span><span class="p">[</span><span class="s2">&quot;source layer&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_layer</span><span class="p">)</span>
                    <span class="n">feature_dict</span><span class="p">[</span><span class="s2">&quot;target layer&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_layer</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">curr_layer</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">feature_dict</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h3 id="binn.explainer.BINNExplainer.explain_average" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">explain_average</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">background_data</span><span class="p">,</span> <span class="n">nr_iterations</span><span class="p">,</span> <span class="n">max_epochs</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">fast_train</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes the SHAP explanations for the given test_data by averaging the Shapley values over multiple iterations.
For each iteration, the model's parameters are randomly initialized and trained on the provided data using
the provided trainer and dataloader. The feature importances are then aggregated and returned in a pandas dataframe.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>test_data</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The input data for which to generate the explanations.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>background_data</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The background data to use for computing the Shapley values.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>nr_iterations</code></td>
          <td>
                <code>int</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The number of iterations to use for averaging the Shapley values.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>trainer</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The PyTorch Lightning trainer to use for training the model.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>dataloader</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The PyTorch DataLoader to use for loading the data.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>



  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><span title="pandas.DataFrame">DataFrame</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>pd.DataFrame: A dataframe containing the aggregated SHAP feature importances.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>binn/explainer.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">explain_average</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">test_data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">background_data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">nr_iterations</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">max_epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">dataloader</span><span class="p">,</span>
    <span class="n">fast_train</span> <span class="p">:</span> <span class="nb">bool</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the SHAP explanations for the given test_data by averaging the Shapley values over multiple iterations.</span>
<span class="sd">    For each iteration, the model&#39;s parameters are randomly initialized and trained on the provided data using</span>
<span class="sd">    the provided trainer and dataloader. The feature importances are then aggregated and returned in a pandas dataframe.</span>

<span class="sd">    Args:</span>
<span class="sd">        test_data (torch.Tensor): The input data for which to generate the explanations.</span>
<span class="sd">        background_data (torch.Tensor): The background data to use for computing the Shapley values.</span>
<span class="sd">        nr_iterations (int): The number of iterations to use for averaging the Shapley values.</span>
<span class="sd">        trainer: The PyTorch Lightning trainer to use for training the model.</span>
<span class="sd">        dataloader: The PyTorch DataLoader to use for loading the data.</span>

<span class="sd">    Returns:</span>
<span class="sd">        pd.DataFrame: A dataframe containing the aggregated SHAP feature importances.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dfs</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nr_iterations</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iteration </span><span class="si">{</span><span class="n">iteration</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">reset_params</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">fast_train</span><span class="p">:</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">configure_optimizers</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fast_train</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">max_epochs</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="n">max_epochs</span><span class="p">)</span>
            <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">)</span>
        <span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">explain</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">background_data</span><span class="p">)</span>
        <span class="n">dfs</span><span class="p">[</span><span class="n">iteration</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span>

    <span class="n">col_names</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;value_</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">dfs</span><span class="o">.</span><span class="n">keys</span><span class="p">())))]</span>
    <span class="n">values</span> <span class="o">=</span> <span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">values</span> <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">dfs</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
    <span class="n">values_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">values_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">dfs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;value&quot;</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="n">col_names</span><span class="p">]</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">T</span>
    <span class="n">df</span><span class="p">[</span><span class="s2">&quot;value_mean&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">values_mean</span>
    <span class="n">df</span><span class="p">[</span><span class="s2">&quot;values_std&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">values_std</span>
    <span class="n">df</span><span class="p">[</span><span class="s2">&quot;value&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">values_mean</span>
    <span class="k">return</span> <span class="n">df</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h3 id="binn.explainer.BINNExplainer.explain_input" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">explain_input</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">background_data</span><span class="p">)</span></code>

</h3>


  <div class="doc doc-contents ">
  
      <p>Computes the SHAP explanations for the given test_data for a specific layer in the model by computing the
Shapley values for each feature using the provided background_data. The feature importances are then returned
in a dictionary.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>test_data</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The input data for which to generate the explanations.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>background_data</code></td>
          <td>
                <code><span title="torch.Tensor">Tensor</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The background data to use for computing the Shapley values.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>layer</code></td>
          <td>
                <code>int</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The index of the layer for which to compute the SHAP explanations.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>



  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
<th>Name</th>        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
<td><code>dict</code></td>          <td>
                <code>dict</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>A dictionary containing the SHAP feature importances.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>binn/explainer.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">explain_input</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">test_data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">background_data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the SHAP explanations for the given test_data for a specific layer in the model by computing the</span>
<span class="sd">    Shapley values for each feature using the provided background_data. The feature importances are then returned</span>
<span class="sd">    in a dictionary.</span>

<span class="sd">    Args:</span>
<span class="sd">        test_data (torch.Tensor): The input data for which to generate the explanations.</span>
<span class="sd">        background_data (torch.Tensor): The background data to use for computing the Shapley values.</span>
<span class="sd">        layer (int): The index of the layer for which to compute the SHAP explanations.</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict: A dictionary containing the SHAP feature importances.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">DeepExplainer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">background_data</span><span class="p">)</span>
    <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>

    <span class="n">shap_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;features&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layer_names</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s2">&quot;shap_values&quot;</span><span class="p">:</span> <span class="n">shap_values</span><span class="p">}</span>

    <span class="k">return</span> <span class="n">shap_dict</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>




  </div>

  </div>

</div>


</section>

</div> <!-- end of page-inner -->
</div> <!-- end of page-wrapper -->

</div> <!-- end of body-inner -->

</div> <!-- end of book-body -->
<script src="../../js/main.js"></script>
<script src="../../js/gitbook.min.js"></script>
<script src="../../js/theme.min.js"></script>
</body>
</html>