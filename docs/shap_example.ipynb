{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] BINN is on device: cpu\n",
      "Mapping group labels: {np.int64(1): 0, np.int64(2): 1}\n",
      "[Epoch 1/50] Train Loss: 0.7530, Train Accuracy: 0.5616\n",
      "[Epoch 1/50] Val Loss: 0.6930, Val Accuracy: 0.5312\n",
      "[Epoch 2/50] Train Loss: 0.7637, Train Accuracy: 0.5778\n",
      "[Epoch 2/50] Val Loss: 0.6928, Val Accuracy: 0.5312\n",
      "[Epoch 3/50] Train Loss: 0.8138, Train Accuracy: 0.4334\n",
      "[Epoch 3/50] Val Loss: 0.6926, Val Accuracy: 0.5312\n",
      "[Epoch 4/50] Train Loss: 0.7063, Train Accuracy: 0.5778\n",
      "[Epoch 4/50] Val Loss: 0.6927, Val Accuracy: 0.5312\n",
      "[Epoch 5/50] Train Loss: 0.7464, Train Accuracy: 0.5603\n",
      "[Epoch 5/50] Val Loss: 0.6923, Val Accuracy: 0.5312\n",
      "[Epoch 6/50] Train Loss: 0.7427, Train Accuracy: 0.6241\n",
      "[Epoch 6/50] Val Loss: 0.6918, Val Accuracy: 0.5312\n",
      "[Epoch 7/50] Train Loss: 0.7326, Train Accuracy: 0.5379\n",
      "[Epoch 7/50] Val Loss: 0.6915, Val Accuracy: 0.5312\n",
      "[Epoch 8/50] Train Loss: 0.7740, Train Accuracy: 0.5528\n",
      "[Epoch 8/50] Val Loss: 0.6914, Val Accuracy: 0.4375\n",
      "[Epoch 9/50] Train Loss: 0.7307, Train Accuracy: 0.5472\n",
      "[Epoch 9/50] Val Loss: 0.6882, Val Accuracy: 0.5000\n",
      "[Epoch 10/50] Train Loss: 0.7534, Train Accuracy: 0.5972\n",
      "[Epoch 10/50] Val Loss: 0.6826, Val Accuracy: 0.5938\n",
      "[Epoch 11/50] Train Loss: 0.6816, Train Accuracy: 0.6672\n",
      "[Epoch 11/50] Val Loss: 0.6674, Val Accuracy: 0.5938\n",
      "[Epoch 12/50] Train Loss: 0.6362, Train Accuracy: 0.7037\n",
      "[Epoch 12/50] Val Loss: 0.6382, Val Accuracy: 0.6406\n",
      "[Epoch 13/50] Train Loss: 0.6879, Train Accuracy: 0.6097\n",
      "[Epoch 13/50] Val Loss: 0.6127, Val Accuracy: 0.6875\n",
      "[Epoch 14/50] Train Loss: 0.6156, Train Accuracy: 0.6534\n",
      "[Epoch 14/50] Val Loss: 0.5904, Val Accuracy: 0.6875\n",
      "[Epoch 15/50] Train Loss: 0.6612, Train Accuracy: 0.6491\n",
      "[Epoch 15/50] Val Loss: 0.5740, Val Accuracy: 0.7031\n",
      "[Epoch 16/50] Train Loss: 0.6389, Train Accuracy: 0.6422\n",
      "[Epoch 16/50] Val Loss: 0.5590, Val Accuracy: 0.7031\n",
      "[Epoch 17/50] Train Loss: 0.5901, Train Accuracy: 0.6998\n",
      "[Epoch 17/50] Val Loss: 0.5595, Val Accuracy: 0.7031\n",
      "[Epoch 18/50] Train Loss: 0.6108, Train Accuracy: 0.6886\n",
      "[Epoch 18/50] Val Loss: 0.5568, Val Accuracy: 0.7188\n",
      "[Epoch 19/50] Train Loss: 0.5467, Train Accuracy: 0.7586\n",
      "[Epoch 19/50] Val Loss: 0.5575, Val Accuracy: 0.7188\n",
      "[Epoch 20/50] Train Loss: 0.5645, Train Accuracy: 0.7304\n",
      "[Epoch 20/50] Val Loss: 0.5614, Val Accuracy: 0.7188\n",
      "[Epoch 21/50] Train Loss: 0.6236, Train Accuracy: 0.6698\n",
      "[Epoch 21/50] Val Loss: 0.5370, Val Accuracy: 0.7344\n",
      "[Epoch 22/50] Train Loss: 0.5858, Train Accuracy: 0.6836\n",
      "[Epoch 22/50] Val Loss: 0.5332, Val Accuracy: 0.7344\n",
      "[Epoch 23/50] Train Loss: 0.5300, Train Accuracy: 0.7474\n",
      "[Epoch 23/50] Val Loss: 0.5402, Val Accuracy: 0.7188\n",
      "[Epoch 24/50] Train Loss: 0.5313, Train Accuracy: 0.7330\n",
      "[Epoch 24/50] Val Loss: 0.5036, Val Accuracy: 0.7344\n",
      "[Epoch 25/50] Train Loss: 0.5284, Train Accuracy: 0.7037\n",
      "[Epoch 25/50] Val Loss: 0.4915, Val Accuracy: 0.7188\n",
      "[Epoch 26/50] Train Loss: 0.5190, Train Accuracy: 0.7580\n",
      "[Epoch 26/50] Val Loss: 0.4730, Val Accuracy: 0.7188\n",
      "[Epoch 27/50] Train Loss: 0.5789, Train Accuracy: 0.7530\n",
      "[Epoch 27/50] Val Loss: 0.4468, Val Accuracy: 0.7344\n",
      "[Epoch 28/50] Train Loss: 0.5566, Train Accuracy: 0.7211\n",
      "[Epoch 28/50] Val Loss: 0.4326, Val Accuracy: 0.7344\n",
      "[Epoch 29/50] Train Loss: 0.5168, Train Accuracy: 0.7679\n",
      "[Epoch 29/50] Val Loss: 0.4216, Val Accuracy: 0.7188\n",
      "[Epoch 30/50] Train Loss: 0.5252, Train Accuracy: 0.7955\n",
      "[Epoch 30/50] Val Loss: 0.4053, Val Accuracy: 0.7812\n",
      "[Epoch 31/50] Train Loss: 0.4350, Train Accuracy: 0.8106\n",
      "[Epoch 31/50] Val Loss: 0.3897, Val Accuracy: 0.7969\n",
      "[Epoch 32/50] Train Loss: 0.4749, Train Accuracy: 0.7905\n",
      "[Epoch 32/50] Val Loss: 0.3880, Val Accuracy: 0.7969\n",
      "[Epoch 33/50] Train Loss: 0.4503, Train Accuracy: 0.7942\n",
      "[Epoch 33/50] Val Loss: 0.3899, Val Accuracy: 0.7812\n",
      "[Epoch 34/50] Train Loss: 0.4743, Train Accuracy: 0.7524\n",
      "[Epoch 34/50] Val Loss: 0.3890, Val Accuracy: 0.7188\n",
      "[Epoch 35/50] Train Loss: 0.4933, Train Accuracy: 0.7511\n",
      "[Epoch 35/50] Val Loss: 0.3916, Val Accuracy: 0.7188\n",
      "[Epoch 36/50] Train Loss: 0.4260, Train Accuracy: 0.8155\n",
      "[Epoch 36/50] Val Loss: 0.3919, Val Accuracy: 0.7812\n",
      "[Epoch 37/50] Train Loss: 0.4921, Train Accuracy: 0.7780\n",
      "[Epoch 37/50] Val Loss: 0.3995, Val Accuracy: 0.7812\n",
      "[Epoch 38/50] Train Loss: 0.4785, Train Accuracy: 0.7899\n",
      "[Epoch 38/50] Val Loss: 0.4311, Val Accuracy: 0.7812\n",
      "[Epoch 39/50] Train Loss: 0.4193, Train Accuracy: 0.8037\n",
      "[Epoch 39/50] Val Loss: 0.4057, Val Accuracy: 0.7812\n",
      "[Epoch 40/50] Train Loss: 0.4524, Train Accuracy: 0.8155\n",
      "[Epoch 40/50] Val Loss: 0.3801, Val Accuracy: 0.7812\n",
      "[Epoch 41/50] Train Loss: 0.4385, Train Accuracy: 0.8024\n",
      "[Epoch 41/50] Val Loss: 0.3854, Val Accuracy: 0.8438\n",
      "[Epoch 42/50] Train Loss: 0.4555, Train Accuracy: 0.7942\n",
      "[Epoch 42/50] Val Loss: 0.3848, Val Accuracy: 0.7812\n",
      "[Epoch 43/50] Train Loss: 0.4801, Train Accuracy: 0.7636\n",
      "[Epoch 43/50] Val Loss: 0.3915, Val Accuracy: 0.7812\n",
      "[Epoch 44/50] Train Loss: 0.3855, Train Accuracy: 0.8655\n",
      "[Epoch 44/50] Val Loss: 0.3833, Val Accuracy: 0.7812\n",
      "[Epoch 45/50] Train Loss: 0.4239, Train Accuracy: 0.8168\n",
      "[Epoch 45/50] Val Loss: 0.3954, Val Accuracy: 0.7812\n",
      "[Epoch 46/50] Train Loss: 0.4129, Train Accuracy: 0.8392\n",
      "[Epoch 46/50] Val Loss: 0.3869, Val Accuracy: 0.7812\n",
      "[Epoch 47/50] Train Loss: 0.4480, Train Accuracy: 0.8024\n",
      "[Epoch 47/50] Val Loss: 0.3690, Val Accuracy: 0.7969\n",
      "[Epoch 48/50] Train Loss: 0.4744, Train Accuracy: 0.7912\n",
      "[Epoch 48/50] Val Loss: 0.3535, Val Accuracy: 0.8750\n",
      "[Epoch 49/50] Train Loss: 0.3950, Train Accuracy: 0.8017\n",
      "[Epoch 49/50] Val Loss: 0.3549, Val Accuracy: 0.8750\n",
      "[Epoch 50/50] Train Loss: 0.4175, Train Accuracy: 0.8086\n",
      "[Epoch 50/50] Val Loss: 0.3634, Val Accuracy: 0.8125\n"
     ]
    }
   ],
   "source": [
    "from binn import BINN, BINNDataLoader, BINNTrainer\n",
    "import pandas as pd\n",
    "\n",
    "# Load your data\n",
    "data_matrix = pd.read_csv(\"../data/test_qm.csv\")\n",
    "design_matrix = pd.read_csv(\"../data/design_matrix.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Initialize BINN\n",
    "binn = BINN(data_matrix=data_matrix, network_source=\"reactome\", n_layers=4, dropout=0.2)\n",
    "\n",
    "## Initialize DataLoader\n",
    "binn_dataloader = BINNDataLoader(binn)\n",
    "\n",
    "# Create DataLoaders\n",
    "dataloaders = binn_dataloader.create_dataloaders(\n",
    "    data_matrix=data_matrix,\n",
    "    design_matrix=design_matrix,\n",
    "    feature_column=\"Protein\",\n",
    "    group_column=\"group\",\n",
    "    sample_column=\"sample\",\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "# Train the model\n",
    "trainer = BINNTrainer(binn)\n",
    "trainer.fit(dataloaders=dataloaders, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_layer</th>\n",
       "      <th>target_layer</th>\n",
       "      <th>source_node</th>\n",
       "      <th>target_node</th>\n",
       "      <th>class_idx</th>\n",
       "      <th>importance</th>\n",
       "      <th>normalized_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0M8Q6</td>\n",
       "      <td>R-HSA-166663</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004052</td>\n",
       "      <td>0.001013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0M8Q6</td>\n",
       "      <td>R-HSA-166663</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007045</td>\n",
       "      <td>0.001761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0M8Q6</td>\n",
       "      <td>R-HSA-198933</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004052</td>\n",
       "      <td>0.001013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0M8Q6</td>\n",
       "      <td>R-HSA-198933</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007045</td>\n",
       "      <td>0.001761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0M8Q6</td>\n",
       "      <td>R-HSA-2029481</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004052</td>\n",
       "      <td>0.001013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7079</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>R-HSA-9612973</td>\n",
       "      <td>output_node</td>\n",
       "      <td>1</td>\n",
       "      <td>0.220133</td>\n",
       "      <td>0.094806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7080</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>R-HSA-9709957</td>\n",
       "      <td>output_node</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054674</td>\n",
       "      <td>0.027337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7081</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>R-HSA-9709957</td>\n",
       "      <td>output_node</td>\n",
       "      <td>1</td>\n",
       "      <td>0.247149</td>\n",
       "      <td>0.123574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7082</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>R-HSA-9748784</td>\n",
       "      <td>output_node</td>\n",
       "      <td>0</td>\n",
       "      <td>0.096502</td>\n",
       "      <td>0.032167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7083</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>R-HSA-9748784</td>\n",
       "      <td>output_node</td>\n",
       "      <td>1</td>\n",
       "      <td>0.225761</td>\n",
       "      <td>0.075254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7084 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      source_layer  target_layer    source_node    target_node  class_idx  \\\n",
       "0                0             1         A0M8Q6   R-HSA-166663          0   \n",
       "1                0             1         A0M8Q6   R-HSA-166663          1   \n",
       "2                0             1         A0M8Q6   R-HSA-198933          0   \n",
       "3                0             1         A0M8Q6   R-HSA-198933          1   \n",
       "4                0             1         A0M8Q6  R-HSA-2029481          0   \n",
       "...            ...           ...            ...            ...        ...   \n",
       "7079             4             5  R-HSA-9612973    output_node          1   \n",
       "7080             4             5  R-HSA-9709957    output_node          0   \n",
       "7081             4             5  R-HSA-9709957    output_node          1   \n",
       "7082             4             5  R-HSA-9748784    output_node          0   \n",
       "7083             4             5  R-HSA-9748784    output_node          1   \n",
       "\n",
       "      importance  normalized_importance  \n",
       "0       0.004052               0.001013  \n",
       "1       0.007045               0.001761  \n",
       "2       0.004052               0.001013  \n",
       "3       0.007045               0.001761  \n",
       "4       0.004052               0.001013  \n",
       "...          ...                    ...  \n",
       "7079    0.220133               0.094806  \n",
       "7080    0.054674               0.027337  \n",
       "7081    0.247149               0.123574  \n",
       "7082    0.096502               0.032167  \n",
       "7083    0.225761               0.075254  \n",
       "\n",
       "[7084 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from binn import BINNExplainer\n",
    "\n",
    "explainer = BINNExplainer(binn)\n",
    "single_explanations = explainer.explain_single(dataloaders, split=\"val\")\n",
    "normalized_single_explanations = explainer.normalize_importances(single_explanations, method=\"fan\")\n",
    "normalized_single_explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              node_id         x         y\n",
      "0           nOther_l1  0.003636  0.950000\n",
      "1          nP12814_l0  0.003636  0.799911\n",
      "2          nP35555_l0  0.003636  0.711032\n",
      "3          nP23141_l0  0.003636  0.622153\n",
      "4          nP27797_l0  0.003636  0.533274\n",
      "5          nP15291_l0  0.003636  0.444395\n",
      "6          nP11142_l0  0.003636  0.355516\n",
      "7          nP60900_l0  0.003636  0.266637\n",
      "8          nP02452_l0  0.003636  0.177758\n",
      "9          nP25788_l0  0.003636  0.088879\n",
      "10         nP60709_l0  0.003636  0.000000\n",
      "11          nOther_l2  0.185455  0.950000\n",
      "12   nR-HSA-983170_l1  0.185455  0.799911\n",
      "13    nR-HSA-73728_l1  0.185455  0.711032\n",
      "14   nR-HSA-114452_l1  0.185455  0.622153\n",
      "15  nR-HSA-2173789_l1  0.185455  0.533274\n",
      "16    nR-HSA-69613_l1  0.185455  0.444395\n",
      "17   nR-HSA-975634_l1  0.185455  0.355516\n",
      "18   nR-HSA-446388_l1  0.185455  0.266637\n",
      "19  nR-HSA-2173793_l1  0.185455  0.177758\n",
      "20  nR-HSA-5693567_l1  0.185455  0.088879\n",
      "21    nR-HSA-72163_l1  0.185455  0.000000\n",
      "22          nOther_l3  0.367273  0.950000\n",
      "23  nR-HSA-5617472_l2  0.367273  0.799911\n",
      "24  nR-HSA-9823587_l2  0.367273  0.711032\n",
      "25  nR-HSA-2453902_l2  0.367273  0.622153\n",
      "26    nR-HSA-69615_l2  0.367273  0.533274\n",
      "27  nR-HSA-3214842_l2  0.367273  0.444395\n",
      "28  nR-HSA-2534343_l2  0.367273  0.355516\n",
      "29  nR-HSA-5693571_l2  0.367273  0.266637\n",
      "30   nR-HSA-446353_l2  0.367273  0.177758\n",
      "31  nR-HSA-5693538_l2  0.367273  0.088879\n",
      "32    nR-HSA-72172_l2  0.367273  0.000000\n",
      "33          nOther_l4  0.549091  0.950000\n",
      "34  nR-HSA-9671793_l3  0.549091  0.799911\n",
      "35   nR-HSA-446728_l3  0.549091  0.711032\n",
      "36   nR-HSA-112315_l3  0.549091  0.622153\n",
      "37    nR-HSA-69620_l3  0.549091  0.533274\n",
      "38   nR-HSA-109581_l3  0.549091  0.444395\n",
      "39  nR-HSA-1187000_l3  0.549091  0.355516\n",
      "40  nR-HSA-9754706_l3  0.549091  0.266637\n",
      "41  nR-HSA-3247509_l3  0.549091  0.177758\n",
      "42    nR-HSA-72203_l3  0.549091  0.088879\n",
      "43  nR-HSA-9615710_l3  0.549091  0.000000\n",
      "44          nOther_l5  0.730909  0.950000\n",
      "45    nR-HSA-74160_l4  0.730909  0.799911\n",
      "46  nR-HSA-9748784_l4  0.730909  0.711032\n",
      "47  nR-HSA-1640170_l4  0.730909  0.622153\n",
      "48  nR-HSA-4839726_l4  0.730909  0.533274\n",
      "49   nR-HSA-392499_l4  0.730909  0.444395\n",
      "50   nR-HSA-168256_l4  0.730909  0.355516\n",
      "51   nR-HSA-162582_l4  0.730909  0.266637\n",
      "52  nR-HSA-9612973_l4  0.730909  0.177758\n",
      "53  nR-HSA-8953854_l4  0.730909  0.088879\n",
      "54  nR-HSA-1474244_l4  0.730909  0.000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "arrangement": "snap",
         "link": {
          "color": [
           "rgba(163,15,21,0.75)",
           "rgba(163,15,21,0.75)",
           "rgba(213,34,33,0.75)",
           "rgba(213,34,33,0.75)",
           "rgba(213,34,33,0.75)",
           "rgba(213,34,33,0.75)",
           "rgba(255,243,237,0.75)",
           "rgba(255,243,237,0.75)",
           "rgba(255,243,237,0.75)",
           "rgba(255,243,237,0.75)",
           "rgba(252,194,170,0.75)",
           "rgba(252,194,170,0.75)",
           "rgba(255,240,232,0.75)",
           "rgba(255,240,232,0.75)",
           "rgba(150,11,19,0.75)",
           "rgba(150,11,19,0.75)",
           "rgba(150,11,19,0.75)",
           "rgba(150,11,19,0.75)",
           "rgba(255,236,228,0.75)",
           "rgba(255,236,228,0.75)",
           "rgba(255,236,228,0.75)",
           "rgba(255,236,228,0.75)",
           "rgba(255,242,235,0.75)",
           "rgba(255,242,235,0.75)",
           "rgba(255,242,235,0.75)",
           "rgba(255,242,235,0.75)",
           "rgba(103,0,13,0.75)",
           "rgba(103,0,13,0.75)",
           "rgba(209,30,31,0.75)",
           "rgba(209,30,31,0.75)",
           "rgba(209,30,31,0.75)",
           "rgba(209,30,31,0.75)",
           "rgba(253,210,191,0.75)",
           "rgba(253,210,191,0.75)",
           "rgba(252,164,134,0.75)",
           "rgba(252,164,134,0.75)",
           "rgba(224,44,38,0.75)",
           "rgba(224,44,38,0.75)",
           "rgba(251,110,78,0.75)",
           "rgba(251,110,78,0.75)",
           "rgba(193,22,27,0.75)",
           "rgba(193,22,27,0.75)",
           "rgba(252,160,130,0.75)",
           "rgba(252,160,130,0.75)",
           "rgba(103,0,13,0.75)",
           "rgba(103,0,13,0.75)",
           "rgba(254,225,211,0.75)",
           "rgba(254,225,211,0.75)",
           "rgba(252,155,124,0.75)",
           "rgba(252,155,124,0.75)",
           "rgba(254,226,213,0.75)",
           "rgba(254,226,213,0.75)",
           "rgba(253,210,191,0.75)",
           "rgba(253,210,191,0.75)",
           "rgba(252,142,110,0.75)",
           "rgba(252,142,110,0.75)",
           "rgba(252,143,111,0.75)",
           "rgba(252,143,111,0.75)",
           "rgba(251,123,91,0.75)",
           "rgba(251,123,91,0.75)",
           "rgba(254,219,204,0.75)",
           "rgba(254,219,204,0.75)",
           "rgba(197,23,28,0.75)",
           "rgba(197,23,28,0.75)",
           "rgba(252,139,107,0.75)",
           "rgba(252,139,107,0.75)",
           "rgba(252,174,146,0.75)",
           "rgba(252,174,146,0.75)",
           "rgba(103,0,13,0.75)",
           "rgba(103,0,13,0.75)",
           "rgba(254,218,202,0.75)",
           "rgba(254,218,202,0.75)",
           "rgba(252,170,141,0.75)",
           "rgba(252,170,141,0.75)",
           "rgba(253,204,184,0.75)",
           "rgba(253,204,184,0.75)",
           "rgba(252,167,139,0.75)",
           "rgba(252,167,139,0.75)",
           "rgba(251,118,86,0.75)",
           "rgba(251,118,86,0.75)",
           "rgba(253,215,198,0.75)",
           "rgba(253,215,198,0.75)",
           "rgba(252,173,144,0.75)",
           "rgba(252,173,144,0.75)",
           "rgba(170,16,22,0.75)",
           "rgba(170,16,22,0.75)",
           "rgba(103,0,13,0.75)",
           "rgba(103,0,13,0.75)",
           "rgba(254,222,207,0.75)",
           "rgba(254,222,207,0.75)",
           "rgba(252,149,118,0.75)",
           "rgba(252,149,118,0.75)",
           "rgba(103,0,13,0.75)",
           "rgba(103,0,13,0.75)",
           "rgba(209,30,31,0.75)",
           "rgba(209,30,31,0.75)",
           "rgba(252,161,131,0.75)",
           "rgba(252,161,131,0.75)",
           "rgba(252,132,100,0.75)",
           "rgba(252,132,100,0.75)",
           "rgba(252,139,107,0.75)",
           "rgba(252,139,107,0.75)",
           "rgba(252,153,122,0.75)",
           "rgba(252,153,122,0.75)",
           "rgba(252,176,149,0.75)",
           "rgba(252,176,149,0.75)",
           "rgba(103,0,13,0.75)",
           "rgba(103,0,13,0.75)",
           "rgba(193,22,27,0.75)",
           "rgba(193,22,27,0.75)",
           "rgba(252,166,137,0.75)",
           "rgba(252,166,137,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)"
          ],
          "source": [
           0,
           0,
           1,
           1,
           1,
           1,
           2,
           2,
           2,
           2,
           3,
           3,
           4,
           4,
           5,
           5,
           5,
           5,
           6,
           6,
           6,
           6,
           7,
           7,
           7,
           7,
           8,
           8,
           9,
           9,
           9,
           9,
           10,
           10,
           11,
           11,
           12,
           12,
           13,
           13,
           14,
           14,
           15,
           15,
           16,
           16,
           17,
           17,
           18,
           18,
           19,
           19,
           20,
           20,
           21,
           21,
           22,
           22,
           23,
           23,
           24,
           24,
           25,
           25,
           26,
           26,
           27,
           27,
           28,
           28,
           29,
           29,
           30,
           30,
           31,
           31,
           32,
           32,
           33,
           33,
           34,
           34,
           35,
           35,
           36,
           36,
           37,
           37,
           38,
           38,
           39,
           39,
           40,
           40,
           41,
           41,
           42,
           42,
           43,
           43,
           44,
           44,
           45,
           45,
           46,
           46,
           47,
           47,
           48,
           48,
           49,
           49,
           50,
           50,
           50,
           50,
           50,
           50,
           50,
           50,
           50,
           50,
           50,
           50,
           50,
           50,
           50,
           50,
           50,
           50,
           51,
           51,
           51,
           51,
           51,
           51,
           51,
           51,
           52,
           52,
           52,
           52,
           52,
           52,
           52,
           52,
           52,
           52,
           52,
           52,
           52,
           52,
           53,
           53,
           53,
           53,
           53,
           53,
           53,
           53,
           53,
           53,
           53,
           53,
           53,
           53,
           53,
           53,
           53,
           53,
           53,
           53,
           54,
           54
          ],
          "target": [
           51,
           51,
           51,
           51,
           16,
           16,
           51,
           51,
           13,
           13,
           51,
           51,
           51,
           51,
           51,
           51,
           15,
           15,
           51,
           51,
           19,
           19,
           51,
           51,
           11,
           11,
           51,
           51,
           51,
           51,
           15,
           15,
           52,
           52,
           52,
           52,
           52,
           52,
           23,
           23,
           25,
           25,
           27,
           27,
           28,
           28,
           52,
           52,
           52,
           52,
           52,
           52,
           53,
           53,
           32,
           32,
           33,
           33,
           34,
           34,
           53,
           53,
           53,
           53,
           53,
           53,
           35,
           35,
           36,
           36,
           38,
           38,
           54,
           54,
           54,
           54,
           54,
           54,
           45,
           45,
           54,
           54,
           42,
           42,
           47,
           47,
           48,
           48,
           54,
           54,
           49,
           49,
           55,
           55,
           55,
           55,
           55,
           55,
           55,
           55,
           55,
           55,
           55,
           55,
           55,
           55,
           55,
           55,
           55,
           55,
           55,
           55,
           51,
           51,
           18,
           18,
           17,
           17,
           11,
           11,
           12,
           12,
           19,
           19,
           15,
           15,
           10,
           10,
           14,
           14,
           52,
           52,
           23,
           23,
           27,
           27,
           29,
           29,
           30,
           30,
           31,
           31,
           53,
           53,
           33,
           33,
           34,
           34,
           35,
           35,
           38,
           38,
           54,
           54,
           43,
           43,
           40,
           40,
           42,
           42,
           41,
           41,
           48,
           48,
           46,
           46,
           49,
           49,
           44,
           44,
           47,
           47,
           55,
           55
          ],
          "value": [
           0.07670631995286359,
           0.04064275248645518,
           0.08847779614504146,
           0.09376221114653384,
           0.005529862259065091,
           0.005860138196658365,
           0.0023096140772635872,
           0.01327915748595375,
           0.0005774035193158968,
           0.0033197893714884373,
           0.007194144100220338,
           0.029156978615145646,
           0.008330979184264066,
           0.0036107409316365954,
           0.05408292071450942,
           0.18263630097080918,
           0.001150700440734243,
           0.00388587874405977,
           0.015093519405941343,
           0.009399036555682923,
           0.0025155865676568905,
           0.0015665060926138205,
           0.00832996043954079,
           0.00816270599754181,
           0.0020824901098851975,
           0.0020406764993854526,
           0.009057532814326408,
           0.123832411039615,
           0.06146008898016901,
           0.1318331745277938,
           0.0013076614676631705,
           0.0028049611601658254,
           0.019980231581725072,
           0.05079998199427646,
           0.04382537980359949,
           0.04352939907163543,
           0.057272594545924795,
           0.06957529165705573,
           0.010519174590295654,
           0.09516533000120884,
           0.0526110341970802,
           0.08610474695270018,
           0.017315896295008036,
           0.07103515809567387,
           0.08741078048219374,
           0.07543423270842438,
           0.050308563434264195,
           0.01458097673651004,
           0.04428489785604911,
           0.04618127137537975,
           0.04575532409099347,
           0.01830973453000146,
           0.013721017646223563,
           0.0620245525328998,
           0.006928611274709579,
           0.09033956519899834,
           0.005278074657734645,
           0.09189397420327333,
           0.01030201700915093,
           0.09320073590134259,
           0.05737583293825613,
           0.01512540322996702,
           0.05152493188845021,
           0.08432720255825618,
           0.03718940016061404,
           0.060865249389522216,
           0.017152984721411375,
           0.07036684162937949,
           0.08560626811552484,
           0.073876962831443,
           0.020190572399339312,
           0.05270980171350353,
           0.025059124413144337,
           0.0637131280556606,
           0.03383123441271462,
           0.04355306066097743,
           0.006398575695196979,
           0.08342862927311892,
           0.005737419784054967,
           0.09989140803409408,
           0.00733971635336715,
           0.06640126516556884,
           0.017288621166325548,
           0.07092326345869523,
           0.07905742842472116,
           0.068225407690578,
           0.07870103168538724,
           0.0838149006352488,
           0.019717800347162775,
           0.05147557700256767,
           0.028580333015550744,
           0.0668620747258648,
           0.05865511193870617,
           0.06717506208451678,
           0.05506287914162912,
           0.05469100097067887,
           0.01691944830512692,
           0.06940880607378996,
           0.06553227767997859,
           0.026223802485984948,
           0.03670944339464802,
           0.053699291401503355,
           0.004774200660001022,
           0.08312126818899113,
           0.06494497872443655,
           0.018823062395202306,
           0.0674619289994424,
           0.05821866162181447,
           0.054794747425424985,
           0.05835522030176654,
           0.0255817496644842,
           0.05984705854187364,
           0.052379730619839485,
           0.04502573442439649,
           0.00041916448572935867,
           0.00036421931053129316,
           0.00009179720764366915,
           0.00021280717247026867,
           0.00006765219041926404,
           0.00008927355671503054,
           0.00013093534207319707,
           0.00006837796731942612,
           0.00008755195152622256,
           0.00003351833005774171,
           0.0003241555699363126,
           0.00023378745771910172,
           0.00010129603358109155,
           0.0001319775454379938,
           0.00007561688544248552,
           0.00016240394916158454,
           0.051889456047270556,
           0.044875756365113366,
           0,
           0,
           0.00000885658312912289,
           0.00003633244198514893,
           0.0008833949496481942,
           0.002306203612853619,
           0.000915998700154494,
           0.0023289378392601723,
           0.0012095496732624227,
           0.0015571286611022676,
           0.052025717577862694,
           0.03699202345563085,
           0.0001648598512782403,
           0.0028702941578118975,
           0.00009581165704617889,
           0.0008667930785375287,
           0.00006209894250084431,
           0.00025474904852165655,
           0.00018169687395296405,
           0.00047434048307779366,
           0.032937977388111966,
           0.021411645240117884,
           0.0034457023754606345,
           0.0013788536781638027,
           0.004250780710277052,
           0.004868228054211527,
           0.00031154313585343875,
           0.001254777156385922,
           0.006730947758421292,
           0.006685489115979101,
           0.0010263385546470957,
           0.0010930284021670247,
           0.0028837012011686185,
           0.0008357857404177416,
           0.0012886377040797268,
           0.0030146951843348607,
           0.0024814401050145354,
           0.0036298990128985327,
           0.0002525674485703414,
           0.00021796203371891634,
           0.044832777372790254,
           0.055167222627209744
          ]
         },
         "node": {
          "color": [
           "rgba(163,15,21,0.75)",
           "rgba(213,34,33,0.75)",
           "rgba(255,243,237,0.75)",
           "rgba(252,194,170,0.75)",
           "rgba(255,240,232,0.75)",
           "rgba(150,11,19,0.75)",
           "rgba(255,236,228,0.75)",
           "rgba(255,242,235,0.75)",
           "rgba(103,0,13,0.75)",
           "rgba(209,30,31,0.75)",
           "rgba(253,210,191,0.75)",
           "rgba(252,164,134,0.75)",
           "rgba(224,44,38,0.75)",
           "rgba(251,110,78,0.75)",
           "rgba(193,22,27,0.75)",
           "rgba(252,160,130,0.75)",
           "rgba(103,0,13,0.75)",
           "rgba(254,225,211,0.75)",
           "rgba(252,155,124,0.75)",
           "rgba(254,226,213,0.75)",
           "rgba(253,210,191,0.75)",
           "rgba(252,142,110,0.75)",
           "rgba(252,143,111,0.75)",
           "rgba(251,123,91,0.75)",
           "rgba(254,219,204,0.75)",
           "rgba(197,23,28,0.75)",
           "rgba(252,139,107,0.75)",
           "rgba(252,174,146,0.75)",
           "rgba(103,0,13,0.75)",
           "rgba(254,218,202,0.75)",
           "rgba(252,170,141,0.75)",
           "rgba(253,204,184,0.75)",
           "rgba(252,167,139,0.75)",
           "rgba(251,118,86,0.75)",
           "rgba(253,215,198,0.75)",
           "rgba(252,173,144,0.75)",
           "rgba(170,16,22,0.75)",
           "rgba(103,0,13,0.75)",
           "rgba(254,222,207,0.75)",
           "rgba(252,149,118,0.75)",
           "rgba(103,0,13,0.75)",
           "rgba(209,30,31,0.75)",
           "rgba(252,161,131,0.75)",
           "rgba(252,132,100,0.75)",
           "rgba(252,139,107,0.75)",
           "rgba(252,153,122,0.75)",
           "rgba(252,176,149,0.75)",
           "rgba(103,0,13,0.75)",
           "rgba(193,22,27,0.75)",
           "rgba(252,166,137,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(236,236,236,0.75)",
           "rgba(0,0,0,1)"
          ],
          "label": [
           "P02452",
           "P11142",
           "P12814",
           "P15291",
           "P23141",
           "P25788",
           "P27797",
           "P35555",
           "P60709",
           "P60900",
           "R-HSA-114452",
           "R-HSA-2173789",
           "R-HSA-2173793",
           "R-HSA-446388",
           "R-HSA-5693567",
           "R-HSA-69613",
           "R-HSA-72163",
           "R-HSA-73728",
           "R-HSA-975634",
           "R-HSA-983170",
           "R-HSA-2453902",
           "R-HSA-2534343",
           "R-HSA-3214842",
           "R-HSA-446353",
           "R-HSA-5617472",
           "R-HSA-5693538",
           "R-HSA-5693571",
           "R-HSA-69615",
           "R-HSA-72172",
           "R-HSA-9823587",
           "R-HSA-109581",
           "R-HSA-112315",
           "R-HSA-1187000",
           "R-HSA-3247509",
           "R-HSA-446728",
           "R-HSA-69620",
           "R-HSA-72203",
           "R-HSA-9615710",
           "R-HSA-9671793",
           "R-HSA-9754706",
           "R-HSA-1474244",
           "R-HSA-162582",
           "R-HSA-1640170",
           "R-HSA-168256",
           "R-HSA-392499",
           "R-HSA-4839726",
           "R-HSA-74160",
           "R-HSA-8953854",
           "R-HSA-9612973",
           "R-HSA-9748784",
           "Other connections 1",
           "Other connections 2",
           "Other connections 3",
           "Other connections 4",
           "Other connections 5",
           "noutput_node_l5"
          ],
          "line": {
           "color": "white",
           "width": 0
          },
          "pad": 15,
          "thickness": 15,
          "x": [
           0.0036363636363636364,
           0.0036363636363636364,
           0.0036363636363636364,
           0.0036363636363636364,
           0.0036363636363636364,
           0.0036363636363636364,
           0.0036363636363636364,
           0.0036363636363636364,
           0.0036363636363636364,
           0.0036363636363636364,
           0.18545454545454546,
           0.18545454545454546,
           0.18545454545454546,
           0.18545454545454546,
           0.18545454545454546,
           0.18545454545454546,
           0.18545454545454546,
           0.18545454545454546,
           0.18545454545454546,
           0.18545454545454546,
           0.36727272727272725,
           0.36727272727272725,
           0.36727272727272725,
           0.36727272727272725,
           0.36727272727272725,
           0.36727272727272725,
           0.36727272727272725,
           0.36727272727272725,
           0.36727272727272725,
           0.36727272727272725,
           0.5490909090909091,
           0.5490909090909091,
           0.5490909090909091,
           0.5490909090909091,
           0.5490909090909091,
           0.5490909090909091,
           0.5490909090909091,
           0.5490909090909091,
           0.5490909090909091,
           0.5490909090909091,
           0.7309090909090908,
           0.7309090909090908,
           0.7309090909090908,
           0.7309090909090908,
           0.7309090909090908,
           0.7309090909090908,
           0.7309090909090908,
           0.7309090909090908,
           0.7309090909090908,
           0.7309090909090908,
           0.0036363636363636364,
           0.18545454545454546,
           0.36727272727272725,
           0.5490909090909091,
           0.7309090909090908,
           0.85
          ],
          "y": [
           0.1777580268859016,
           0.3555160537718032,
           0.7999111209865571,
           0.44439506721475397,
           0.6221530941006556,
           0.0888790134429508,
           0.5332740806577048,
           0.7110321075436064,
           0,
           0.2666370403288524,
           0.6221530941006556,
           0.5332740806577048,
           0.1777580268859016,
           0.2666370403288524,
           0.0888790134429508,
           0.44439506721475397,
           0,
           0.7110321075436064,
           0.3555160537718032,
           0.7999111209865571,
           0.6221530941006556,
           0.3555160537718032,
           0.44439506721475397,
           0.1777580268859016,
           0.7999111209865571,
           0.0888790134429508,
           0.2666370403288524,
           0.5332740806577048,
           0,
           0.7110321075436064,
           0.44439506721475397,
           0.6221530941006556,
           0.3555160537718032,
           0.1777580268859016,
           0.7110321075436064,
           0.5332740806577048,
           0.0888790134429508,
           0,
           0.7999111209865571,
           0.2666370403288524,
           0,
           0.2666370403288524,
           0.6221530941006556,
           0.3555160537718032,
           0.44439506721475397,
           0.5332740806577048,
           0.7999111209865571,
           0.0888790134429508,
           0.1777580268859016,
           0.7110321075436064,
           0.95,
           0.95,
           0.95,
           0.95,
           0.95,
           0.5
          ]
         },
         "orientation": "h",
         "textfont": {
          "family": "Arial",
          "size": 15
         },
         "type": "sankey"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from binn.plot.sankey import SankeyPlotter\n",
    "\n",
    "plotter = SankeyPlotter(\n",
    "    explanations_data=single_explanations,\n",
    "    show_top_n=10,\n",
    "    value_col=\"importance\",\n",
    "    node_cmap=\"Reds\",\n",
    "    edge_cmap=\"coolwarm\"\n",
    ")\n",
    "\n",
    "fig = plotter.plot()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BINNExplainer] Iteration 1/3...\n",
      "[Epoch 1/50] Train Loss: 0.8281, Train Accuracy: 0.5196\n",
      "[Epoch 1/50] Val Loss: 0.6930, Val Accuracy: 0.5312\n",
      "[Epoch 2/50] Train Loss: 0.9235, Train Accuracy: 0.4683\n",
      "[Epoch 2/50] Val Loss: 0.6927, Val Accuracy: 0.5312\n",
      "[Epoch 3/50] Train Loss: 0.8645, Train Accuracy: 0.4478\n",
      "[Epoch 3/50] Val Loss: 0.6926, Val Accuracy: 0.5312\n",
      "[Epoch 4/50] Train Loss: 0.8600, Train Accuracy: 0.4341\n",
      "[Epoch 4/50] Val Loss: 0.6926, Val Accuracy: 0.5312\n",
      "[Epoch 5/50] Train Loss: 0.8760, Train Accuracy: 0.4653\n",
      "[Epoch 5/50] Val Loss: 0.6922, Val Accuracy: 0.5312\n",
      "[Epoch 6/50] Train Loss: 0.8581, Train Accuracy: 0.4728\n",
      "[Epoch 6/50] Val Loss: 0.6920, Val Accuracy: 0.5312\n",
      "[Epoch 7/50] Train Loss: 0.8089, Train Accuracy: 0.5336\n",
      "[Epoch 7/50] Val Loss: 0.6917, Val Accuracy: 0.5312\n",
      "[Epoch 8/50] Train Loss: 0.8094, Train Accuracy: 0.4821\n",
      "[Epoch 8/50] Val Loss: 0.6904, Val Accuracy: 0.5312\n",
      "[Epoch 9/50] Train Loss: 0.8025, Train Accuracy: 0.5216\n",
      "[Epoch 9/50] Val Loss: 0.6870, Val Accuracy: 0.5938\n",
      "[Epoch 10/50] Train Loss: 0.7766, Train Accuracy: 0.4716\n",
      "[Epoch 10/50] Val Loss: 0.6800, Val Accuracy: 0.5781\n",
      "[Epoch 11/50] Train Loss: 0.7630, Train Accuracy: 0.4778\n",
      "[Epoch 11/50] Val Loss: 0.6685, Val Accuracy: 0.5312\n",
      "[Epoch 12/50] Train Loss: 0.7054, Train Accuracy: 0.5791\n",
      "[Epoch 12/50] Val Loss: 0.6533, Val Accuracy: 0.5469\n",
      "[Epoch 13/50] Train Loss: 0.7354, Train Accuracy: 0.5472\n",
      "[Epoch 13/50] Val Loss: 0.6424, Val Accuracy: 0.6406\n",
      "[Epoch 14/50] Train Loss: 0.7215, Train Accuracy: 0.5515\n",
      "[Epoch 14/50] Val Loss: 0.6395, Val Accuracy: 0.6094\n",
      "[Epoch 15/50] Train Loss: 0.6823, Train Accuracy: 0.6022\n",
      "[Epoch 15/50] Val Loss: 0.6444, Val Accuracy: 0.6719\n",
      "[Epoch 16/50] Train Loss: 0.6722, Train Accuracy: 0.6110\n",
      "[Epoch 16/50] Val Loss: 0.6350, Val Accuracy: 0.6719\n",
      "[Epoch 17/50] Train Loss: 0.6755, Train Accuracy: 0.6034\n",
      "[Epoch 17/50] Val Loss: 0.6238, Val Accuracy: 0.6719\n",
      "[Epoch 18/50] Train Loss: 0.6490, Train Accuracy: 0.5985\n",
      "[Epoch 18/50] Val Loss: 0.5954, Val Accuracy: 0.6719\n",
      "[Epoch 19/50] Train Loss: 0.6498, Train Accuracy: 0.6261\n",
      "[Epoch 19/50] Val Loss: 0.5853, Val Accuracy: 0.7188\n",
      "[Epoch 20/50] Train Loss: 0.6435, Train Accuracy: 0.6386\n",
      "[Epoch 20/50] Val Loss: 0.5684, Val Accuracy: 0.7188\n",
      "[Epoch 21/50] Train Loss: 0.6545, Train Accuracy: 0.6116\n",
      "[Epoch 21/50] Val Loss: 0.5446, Val Accuracy: 0.7500\n",
      "[Epoch 22/50] Train Loss: 0.6341, Train Accuracy: 0.6103\n",
      "[Epoch 22/50] Val Loss: 0.5464, Val Accuracy: 0.7344\n",
      "[Epoch 23/50] Train Loss: 0.6324, Train Accuracy: 0.6304\n",
      "[Epoch 23/50] Val Loss: 0.5276, Val Accuracy: 0.7344\n",
      "[Epoch 24/50] Train Loss: 0.6305, Train Accuracy: 0.6422\n",
      "[Epoch 24/50] Val Loss: 0.5301, Val Accuracy: 0.7344\n",
      "[Epoch 25/50] Train Loss: 0.5787, Train Accuracy: 0.7136\n",
      "[Epoch 25/50] Val Loss: 0.5342, Val Accuracy: 0.6562\n",
      "[Epoch 26/50] Train Loss: 0.6138, Train Accuracy: 0.6379\n",
      "[Epoch 26/50] Val Loss: 0.5320, Val Accuracy: 0.6719\n",
      "[Epoch 27/50] Train Loss: 0.6312, Train Accuracy: 0.6304\n",
      "[Epoch 27/50] Val Loss: 0.5395, Val Accuracy: 0.6719\n",
      "[Epoch 28/50] Train Loss: 0.6084, Train Accuracy: 0.6347\n",
      "[Epoch 28/50] Val Loss: 0.4985, Val Accuracy: 0.7031\n",
      "[Epoch 29/50] Train Loss: 0.5863, Train Accuracy: 0.7073\n",
      "[Epoch 29/50] Val Loss: 0.4405, Val Accuracy: 0.8125\n",
      "[Epoch 30/50] Train Loss: 0.5792, Train Accuracy: 0.6961\n",
      "[Epoch 30/50] Val Loss: 0.4327, Val Accuracy: 0.8281\n",
      "[Epoch 31/50] Train Loss: 0.5550, Train Accuracy: 0.7073\n",
      "[Epoch 31/50] Val Loss: 0.4096, Val Accuracy: 0.8438\n",
      "[Epoch 32/50] Train Loss: 0.5670, Train Accuracy: 0.7086\n",
      "[Epoch 32/50] Val Loss: 0.4056, Val Accuracy: 0.8438\n",
      "[Epoch 33/50] Train Loss: 0.5328, Train Accuracy: 0.7323\n",
      "[Epoch 33/50] Val Loss: 0.4010, Val Accuracy: 0.8594\n",
      "[Epoch 34/50] Train Loss: 0.5717, Train Accuracy: 0.6873\n",
      "[Epoch 34/50] Val Loss: 0.3925, Val Accuracy: 0.8594\n",
      "[Epoch 35/50] Train Loss: 0.5273, Train Accuracy: 0.6991\n",
      "[Epoch 35/50] Val Loss: 0.3889, Val Accuracy: 0.8438\n",
      "[Epoch 36/50] Train Loss: 0.5282, Train Accuracy: 0.7461\n",
      "[Epoch 36/50] Val Loss: 0.3863, Val Accuracy: 0.8281\n",
      "[Epoch 37/50] Train Loss: 0.5277, Train Accuracy: 0.7392\n",
      "[Epoch 37/50] Val Loss: 0.4126, Val Accuracy: 0.8125\n",
      "[Epoch 38/50] Train Loss: 0.4792, Train Accuracy: 0.7935\n",
      "[Epoch 38/50] Val Loss: 0.3931, Val Accuracy: 0.8281\n",
      "[Epoch 39/50] Train Loss: 0.4495, Train Accuracy: 0.8218\n",
      "[Epoch 39/50] Val Loss: 0.3712, Val Accuracy: 0.8281\n",
      "[Epoch 40/50] Train Loss: 0.4821, Train Accuracy: 0.7511\n",
      "[Epoch 40/50] Val Loss: 0.3751, Val Accuracy: 0.8125\n",
      "[Epoch 41/50] Train Loss: 0.4909, Train Accuracy: 0.7724\n",
      "[Epoch 41/50] Val Loss: 0.3828, Val Accuracy: 0.8281\n",
      "[Epoch 42/50] Train Loss: 0.4925, Train Accuracy: 0.7899\n",
      "[Epoch 42/50] Val Loss: 0.4104, Val Accuracy: 0.8125\n",
      "[Epoch 43/50] Train Loss: 0.5208, Train Accuracy: 0.7086\n",
      "[Epoch 43/50] Val Loss: 0.4080, Val Accuracy: 0.8125\n",
      "[Epoch 44/50] Train Loss: 0.4868, Train Accuracy: 0.7698\n",
      "[Epoch 44/50] Val Loss: 0.3856, Val Accuracy: 0.7969\n",
      "[Epoch 45/50] Train Loss: 0.4705, Train Accuracy: 0.7692\n",
      "[Epoch 45/50] Val Loss: 0.3616, Val Accuracy: 0.8125\n",
      "[Epoch 46/50] Train Loss: 0.5006, Train Accuracy: 0.7718\n",
      "[Epoch 46/50] Val Loss: 0.3548, Val Accuracy: 0.8438\n",
      "[Epoch 47/50] Train Loss: 0.5137, Train Accuracy: 0.7550\n",
      "[Epoch 47/50] Val Loss: 0.3444, Val Accuracy: 0.8750\n",
      "[Epoch 48/50] Train Loss: 0.4505, Train Accuracy: 0.7711\n",
      "[Epoch 48/50] Val Loss: 0.3440, Val Accuracy: 0.8750\n",
      "[Epoch 49/50] Train Loss: 0.4467, Train Accuracy: 0.8086\n",
      "[Epoch 49/50] Val Loss: 0.3383, Val Accuracy: 0.8906\n",
      "[Epoch 50/50] Train Loss: 0.4086, Train Accuracy: 0.8612\n",
      "[Epoch 50/50] Val Loss: 0.3379, Val Accuracy: 0.8906\n",
      "[BINNExplainer] Iteration 2/3...\n",
      "[Epoch 1/50] Train Loss: 0.5996, Train Accuracy: 0.7080\n",
      "[Epoch 1/50] Val Loss: 0.6932, Val Accuracy: 0.4688\n",
      "[Epoch 2/50] Train Loss: 0.6114, Train Accuracy: 0.6679\n",
      "[Epoch 2/50] Val Loss: 0.6931, Val Accuracy: 0.4688\n",
      "[Epoch 3/50] Train Loss: 0.6129, Train Accuracy: 0.6817\n",
      "[Epoch 3/50] Val Loss: 0.6930, Val Accuracy: 0.5312\n",
      "[Epoch 4/50] Train Loss: 0.5915, Train Accuracy: 0.7060\n",
      "[Epoch 4/50] Val Loss: 0.6928, Val Accuracy: 0.6562\n",
      "[Epoch 5/50] Train Loss: 0.6394, Train Accuracy: 0.6179\n",
      "[Epoch 5/50] Val Loss: 0.6920, Val Accuracy: 0.5312\n",
      "[Epoch 6/50] Train Loss: 0.5768, Train Accuracy: 0.7817\n",
      "[Epoch 6/50] Val Loss: 0.6903, Val Accuracy: 0.5312\n",
      "[Epoch 7/50] Train Loss: 0.5774, Train Accuracy: 0.6961\n",
      "[Epoch 7/50] Val Loss: 0.6869, Val Accuracy: 0.5312\n",
      "[Epoch 8/50] Train Loss: 0.5661, Train Accuracy: 0.7011\n",
      "[Epoch 8/50] Val Loss: 0.6800, Val Accuracy: 0.5938\n",
      "[Epoch 9/50] Train Loss: 0.5372, Train Accuracy: 0.7323\n",
      "[Epoch 9/50] Val Loss: 0.6668, Val Accuracy: 0.7812\n",
      "[Epoch 10/50] Train Loss: 0.5751, Train Accuracy: 0.7011\n",
      "[Epoch 10/50] Val Loss: 0.6436, Val Accuracy: 0.8281\n",
      "[Epoch 11/50] Train Loss: 0.6287, Train Accuracy: 0.6623\n",
      "[Epoch 11/50] Val Loss: 0.6115, Val Accuracy: 0.7188\n",
      "[Epoch 12/50] Train Loss: 0.5824, Train Accuracy: 0.7129\n",
      "[Epoch 12/50] Val Loss: 0.5751, Val Accuracy: 0.7031\n",
      "[Epoch 13/50] Train Loss: 0.5632, Train Accuracy: 0.6961\n",
      "[Epoch 13/50] Val Loss: 0.5477, Val Accuracy: 0.7031\n",
      "[Epoch 14/50] Train Loss: 0.5566, Train Accuracy: 0.7235\n",
      "[Epoch 14/50] Val Loss: 0.5175, Val Accuracy: 0.7344\n",
      "[Epoch 15/50] Train Loss: 0.5510, Train Accuracy: 0.7573\n",
      "[Epoch 15/50] Val Loss: 0.5092, Val Accuracy: 0.7344\n",
      "[Epoch 16/50] Train Loss: 0.5160, Train Accuracy: 0.7560\n",
      "[Epoch 16/50] Val Loss: 0.5088, Val Accuracy: 0.7344\n",
      "[Epoch 17/50] Train Loss: 0.5067, Train Accuracy: 0.7780\n",
      "[Epoch 17/50] Val Loss: 0.5068, Val Accuracy: 0.7344\n",
      "[Epoch 18/50] Train Loss: 0.4732, Train Accuracy: 0.7636\n",
      "[Epoch 18/50] Val Loss: 0.5091, Val Accuracy: 0.7344\n",
      "[Epoch 19/50] Train Loss: 0.5187, Train Accuracy: 0.7205\n",
      "[Epoch 19/50] Val Loss: 0.4946, Val Accuracy: 0.7500\n",
      "[Epoch 20/50] Train Loss: 0.4972, Train Accuracy: 0.7435\n",
      "[Epoch 20/50] Val Loss: 0.4891, Val Accuracy: 0.7500\n",
      "[Epoch 21/50] Train Loss: 0.4807, Train Accuracy: 0.7886\n",
      "[Epoch 21/50] Val Loss: 0.4682, Val Accuracy: 0.7500\n",
      "[Epoch 22/50] Train Loss: 0.4966, Train Accuracy: 0.7748\n",
      "[Epoch 22/50] Val Loss: 0.4613, Val Accuracy: 0.7500\n",
      "[Epoch 23/50] Train Loss: 0.4975, Train Accuracy: 0.7511\n",
      "[Epoch 23/50] Val Loss: 0.4536, Val Accuracy: 0.7500\n",
      "[Epoch 24/50] Train Loss: 0.4586, Train Accuracy: 0.8011\n",
      "[Epoch 24/50] Val Loss: 0.4573, Val Accuracy: 0.7500\n",
      "[Epoch 25/50] Train Loss: 0.4851, Train Accuracy: 0.7767\n",
      "[Epoch 25/50] Val Loss: 0.4433, Val Accuracy: 0.7500\n",
      "[Epoch 26/50] Train Loss: 0.4622, Train Accuracy: 0.8142\n",
      "[Epoch 26/50] Val Loss: 0.4378, Val Accuracy: 0.7500\n",
      "[Epoch 27/50] Train Loss: 0.4913, Train Accuracy: 0.7612\n",
      "[Epoch 27/50] Val Loss: 0.4322, Val Accuracy: 0.7500\n",
      "[Epoch 28/50] Train Loss: 0.4831, Train Accuracy: 0.8162\n",
      "[Epoch 28/50] Val Loss: 0.4249, Val Accuracy: 0.8125\n",
      "[Epoch 29/50] Train Loss: 0.4997, Train Accuracy: 0.7254\n",
      "[Epoch 29/50] Val Loss: 0.4240, Val Accuracy: 0.8125\n",
      "[Epoch 30/50] Train Loss: 0.4887, Train Accuracy: 0.7606\n",
      "[Epoch 30/50] Val Loss: 0.4245, Val Accuracy: 0.7500\n",
      "[Epoch 31/50] Train Loss: 0.4454, Train Accuracy: 0.8343\n",
      "[Epoch 31/50] Val Loss: 0.4198, Val Accuracy: 0.7500\n",
      "[Epoch 32/50] Train Loss: 0.4520, Train Accuracy: 0.8330\n",
      "[Epoch 32/50] Val Loss: 0.4123, Val Accuracy: 0.8125\n",
      "[Epoch 33/50] Train Loss: 0.3998, Train Accuracy: 0.8405\n",
      "[Epoch 33/50] Val Loss: 0.4115, Val Accuracy: 0.8125\n",
      "[Epoch 34/50] Train Loss: 0.4211, Train Accuracy: 0.8149\n",
      "[Epoch 34/50] Val Loss: 0.4120, Val Accuracy: 0.7969\n",
      "[Epoch 35/50] Train Loss: 0.4318, Train Accuracy: 0.8724\n",
      "[Epoch 35/50] Val Loss: 0.4000, Val Accuracy: 0.8125\n",
      "[Epoch 36/50] Train Loss: 0.4418, Train Accuracy: 0.7856\n",
      "[Epoch 36/50] Val Loss: 0.3988, Val Accuracy: 0.7969\n",
      "[Epoch 37/50] Train Loss: 0.4386, Train Accuracy: 0.8185\n",
      "[Epoch 37/50] Val Loss: 0.3952, Val Accuracy: 0.7969\n",
      "[Epoch 38/50] Train Loss: 0.4247, Train Accuracy: 0.8149\n",
      "[Epoch 38/50] Val Loss: 0.3888, Val Accuracy: 0.8125\n",
      "[Epoch 39/50] Train Loss: 0.3965, Train Accuracy: 0.8392\n",
      "[Epoch 39/50] Val Loss: 0.3807, Val Accuracy: 0.8281\n",
      "[Epoch 40/50] Train Loss: 0.4277, Train Accuracy: 0.8162\n",
      "[Epoch 40/50] Val Loss: 0.3807, Val Accuracy: 0.8125\n",
      "[Epoch 41/50] Train Loss: 0.4177, Train Accuracy: 0.8280\n",
      "[Epoch 41/50] Val Loss: 0.3775, Val Accuracy: 0.8125\n",
      "[Epoch 42/50] Train Loss: 0.4092, Train Accuracy: 0.8800\n",
      "[Epoch 42/50] Val Loss: 0.3685, Val Accuracy: 0.8281\n",
      "[Epoch 43/50] Train Loss: 0.4151, Train Accuracy: 0.8343\n",
      "[Epoch 43/50] Val Loss: 0.3669, Val Accuracy: 0.8281\n",
      "[Epoch 44/50] Train Loss: 0.3988, Train Accuracy: 0.8655\n",
      "[Epoch 44/50] Val Loss: 0.3636, Val Accuracy: 0.8281\n",
      "[Epoch 45/50] Train Loss: 0.4021, Train Accuracy: 0.8293\n",
      "[Epoch 45/50] Val Loss: 0.3758, Val Accuracy: 0.8125\n",
      "[Epoch 46/50] Train Loss: 0.4095, Train Accuracy: 0.8468\n",
      "[Epoch 46/50] Val Loss: 0.3757, Val Accuracy: 0.8125\n",
      "[Epoch 47/50] Train Loss: 0.4157, Train Accuracy: 0.8231\n",
      "[Epoch 47/50] Val Loss: 0.3648, Val Accuracy: 0.8125\n",
      "[Epoch 48/50] Train Loss: 0.4266, Train Accuracy: 0.8280\n",
      "[Epoch 48/50] Val Loss: 0.3592, Val Accuracy: 0.8281\n",
      "[Epoch 49/50] Train Loss: 0.4004, Train Accuracy: 0.8218\n",
      "[Epoch 49/50] Val Loss: 0.3601, Val Accuracy: 0.8125\n",
      "[Epoch 50/50] Train Loss: 0.4286, Train Accuracy: 0.8103\n",
      "[Epoch 50/50] Val Loss: 0.3542, Val Accuracy: 0.8281\n",
      "[BINNExplainer] Iteration 3/3...\n",
      "[Epoch 1/50] Train Loss: 0.6123, Train Accuracy: 0.6636\n",
      "[Epoch 1/50] Val Loss: 0.6930, Val Accuracy: 0.5312\n",
      "[Epoch 2/50] Train Loss: 0.6230, Train Accuracy: 0.7054\n",
      "[Epoch 2/50] Val Loss: 0.6925, Val Accuracy: 0.5312\n",
      "[Epoch 3/50] Train Loss: 0.6568, Train Accuracy: 0.6179\n",
      "[Epoch 3/50] Val Loss: 0.6922, Val Accuracy: 0.5312\n",
      "[Epoch 4/50] Train Loss: 0.5596, Train Accuracy: 0.7498\n",
      "[Epoch 4/50] Val Loss: 0.6914, Val Accuracy: 0.5312\n",
      "[Epoch 5/50] Train Loss: 0.6225, Train Accuracy: 0.6498\n",
      "[Epoch 5/50] Val Loss: 0.6898, Val Accuracy: 0.5312\n",
      "[Epoch 6/50] Train Loss: 0.5880, Train Accuracy: 0.6929\n",
      "[Epoch 6/50] Val Loss: 0.6860, Val Accuracy: 0.5312\n",
      "[Epoch 7/50] Train Loss: 0.5766, Train Accuracy: 0.7060\n",
      "[Epoch 7/50] Val Loss: 0.6779, Val Accuracy: 0.5312\n",
      "[Epoch 8/50] Train Loss: 0.5479, Train Accuracy: 0.6817\n",
      "[Epoch 8/50] Val Loss: 0.6608, Val Accuracy: 0.7500\n",
      "[Epoch 9/50] Train Loss: 0.5737, Train Accuracy: 0.6998\n",
      "[Epoch 9/50] Val Loss: 0.6295, Val Accuracy: 0.8438\n",
      "[Epoch 10/50] Train Loss: 0.5705, Train Accuracy: 0.6955\n",
      "[Epoch 10/50] Val Loss: 0.5830, Val Accuracy: 0.8594\n",
      "[Epoch 11/50] Train Loss: 0.5784, Train Accuracy: 0.7004\n",
      "[Epoch 11/50] Val Loss: 0.5295, Val Accuracy: 0.8906\n",
      "[Epoch 12/50] Train Loss: 0.5868, Train Accuracy: 0.6705\n",
      "[Epoch 12/50] Val Loss: 0.4809, Val Accuracy: 0.8906\n",
      "[Epoch 13/50] Train Loss: 0.5320, Train Accuracy: 0.7448\n",
      "[Epoch 13/50] Val Loss: 0.4452, Val Accuracy: 0.8906\n",
      "[Epoch 14/50] Train Loss: 0.5370, Train Accuracy: 0.7261\n",
      "[Epoch 14/50] Val Loss: 0.4193, Val Accuracy: 0.8750\n",
      "[Epoch 15/50] Train Loss: 0.5735, Train Accuracy: 0.7129\n",
      "[Epoch 15/50] Val Loss: 0.4078, Val Accuracy: 0.8594\n",
      "[Epoch 16/50] Train Loss: 0.5521, Train Accuracy: 0.7004\n",
      "[Epoch 16/50] Val Loss: 0.4032, Val Accuracy: 0.8594\n",
      "[Epoch 17/50] Train Loss: 0.4640, Train Accuracy: 0.7599\n",
      "[Epoch 17/50] Val Loss: 0.4033, Val Accuracy: 0.8281\n",
      "[Epoch 18/50] Train Loss: 0.4758, Train Accuracy: 0.7879\n",
      "[Epoch 18/50] Val Loss: 0.4169, Val Accuracy: 0.8125\n",
      "[Epoch 19/50] Train Loss: 0.4785, Train Accuracy: 0.8004\n",
      "[Epoch 19/50] Val Loss: 0.4243, Val Accuracy: 0.7812\n",
      "[Epoch 20/50] Train Loss: 0.4741, Train Accuracy: 0.8300\n",
      "[Epoch 20/50] Val Loss: 0.4329, Val Accuracy: 0.7500\n",
      "[Epoch 21/50] Train Loss: 0.5024, Train Accuracy: 0.7711\n",
      "[Epoch 21/50] Val Loss: 0.4381, Val Accuracy: 0.7500\n",
      "[Epoch 22/50] Train Loss: 0.4723, Train Accuracy: 0.7849\n",
      "[Epoch 22/50] Val Loss: 0.4466, Val Accuracy: 0.7656\n",
      "[Epoch 23/50] Train Loss: 0.4578, Train Accuracy: 0.8017\n",
      "[Epoch 23/50] Val Loss: 0.4432, Val Accuracy: 0.7500\n",
      "[Epoch 24/50] Train Loss: 0.4895, Train Accuracy: 0.7642\n",
      "[Epoch 24/50] Val Loss: 0.4390, Val Accuracy: 0.7500\n",
      "[Epoch 25/50] Train Loss: 0.5260, Train Accuracy: 0.7455\n",
      "[Epoch 25/50] Val Loss: 0.4320, Val Accuracy: 0.7500\n",
      "[Epoch 26/50] Train Loss: 0.4616, Train Accuracy: 0.7573\n",
      "[Epoch 26/50] Val Loss: 0.4288, Val Accuracy: 0.7500\n",
      "[Epoch 27/50] Train Loss: 0.5043, Train Accuracy: 0.7567\n",
      "[Epoch 27/50] Val Loss: 0.4236, Val Accuracy: 0.7500\n",
      "[Epoch 28/50] Train Loss: 0.4684, Train Accuracy: 0.7754\n",
      "[Epoch 28/50] Val Loss: 0.4128, Val Accuracy: 0.7500\n",
      "[Epoch 29/50] Train Loss: 0.4171, Train Accuracy: 0.8724\n",
      "[Epoch 29/50] Val Loss: 0.4083, Val Accuracy: 0.7500\n",
      "[Epoch 30/50] Train Loss: 0.4070, Train Accuracy: 0.8024\n",
      "[Epoch 30/50] Val Loss: 0.4001, Val Accuracy: 0.7500\n",
      "[Epoch 31/50] Train Loss: 0.4235, Train Accuracy: 0.8336\n",
      "[Epoch 31/50] Val Loss: 0.3899, Val Accuracy: 0.7500\n",
      "[Epoch 32/50] Train Loss: 0.4380, Train Accuracy: 0.8030\n",
      "[Epoch 32/50] Val Loss: 0.3731, Val Accuracy: 0.7812\n",
      "[Epoch 33/50] Train Loss: 0.4155, Train Accuracy: 0.8362\n",
      "[Epoch 33/50] Val Loss: 0.3682, Val Accuracy: 0.7812\n",
      "[Epoch 34/50] Train Loss: 0.4026, Train Accuracy: 0.8412\n",
      "[Epoch 34/50] Val Loss: 0.3676, Val Accuracy: 0.7812\n",
      "[Epoch 35/50] Train Loss: 0.4752, Train Accuracy: 0.7629\n",
      "[Epoch 35/50] Val Loss: 0.3590, Val Accuracy: 0.7812\n",
      "[Epoch 36/50] Train Loss: 0.4261, Train Accuracy: 0.8093\n",
      "[Epoch 36/50] Val Loss: 0.3511, Val Accuracy: 0.7812\n",
      "[Epoch 37/50] Train Loss: 0.4407, Train Accuracy: 0.8116\n",
      "[Epoch 37/50] Val Loss: 0.3445, Val Accuracy: 0.7969\n",
      "[Epoch 38/50] Train Loss: 0.4021, Train Accuracy: 0.8218\n",
      "[Epoch 38/50] Val Loss: 0.3424, Val Accuracy: 0.8594\n",
      "[Epoch 39/50] Train Loss: 0.3917, Train Accuracy: 0.8468\n",
      "[Epoch 39/50] Val Loss: 0.3334, Val Accuracy: 0.8750\n",
      "[Epoch 40/50] Train Loss: 0.3554, Train Accuracy: 0.8899\n",
      "[Epoch 40/50] Val Loss: 0.3307, Val Accuracy: 0.8594\n",
      "[Epoch 41/50] Train Loss: 0.3916, Train Accuracy: 0.8399\n",
      "[Epoch 41/50] Val Loss: 0.3194, Val Accuracy: 0.8750\n",
      "[Epoch 42/50] Train Loss: 0.3862, Train Accuracy: 0.8343\n",
      "[Epoch 42/50] Val Loss: 0.3150, Val Accuracy: 0.8750\n",
      "[Epoch 43/50] Train Loss: 0.3809, Train Accuracy: 0.8737\n",
      "[Epoch 43/50] Val Loss: 0.3324, Val Accuracy: 0.8594\n",
      "[Epoch 44/50] Train Loss: 0.3728, Train Accuracy: 0.8224\n",
      "[Epoch 44/50] Val Loss: 0.3398, Val Accuracy: 0.8594\n",
      "[Epoch 45/50] Train Loss: 0.3557, Train Accuracy: 0.8856\n",
      "[Epoch 45/50] Val Loss: 0.3337, Val Accuracy: 0.8594\n",
      "[Epoch 46/50] Train Loss: 0.3786, Train Accuracy: 0.8705\n",
      "[Epoch 46/50] Val Loss: 0.3359, Val Accuracy: 0.8594\n",
      "[Epoch 47/50] Train Loss: 0.4364, Train Accuracy: 0.8086\n",
      "[Epoch 47/50] Val Loss: 0.3313, Val Accuracy: 0.8594\n",
      "[Epoch 48/50] Train Loss: 0.3969, Train Accuracy: 0.8524\n",
      "[Epoch 48/50] Val Loss: 0.3260, Val Accuracy: 0.8594\n",
      "[Epoch 49/50] Train Loss: 0.3642, Train Accuracy: 0.8356\n",
      "[Epoch 49/50] Val Loss: 0.3242, Val Accuracy: 0.8594\n",
      "[Epoch 50/50] Train Loss: 0.3491, Train Accuracy: 0.8787\n",
      "[Epoch 50/50] Val Loss: 0.3157, Val Accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "average_explanations = explainer.explain(dataloaders, nr_iterations=3, num_epochs=50, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_layer</th>\n",
       "      <th>target_layer</th>\n",
       "      <th>source_node</th>\n",
       "      <th>target_node</th>\n",
       "      <th>class_idx</th>\n",
       "      <th>importance</th>\n",
       "      <th>importance_0</th>\n",
       "      <th>importance_1</th>\n",
       "      <th>importance_2</th>\n",
       "      <th>importance_mean</th>\n",
       "      <th>importance_std</th>\n",
       "      <th>normalized_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0M8Q6</td>\n",
       "      <td>R-HSA-166663</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.001778</td>\n",
       "      <td>0.011938</td>\n",
       "      <td>0.005106</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.004229</td>\n",
       "      <td>0.001569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0M8Q6</td>\n",
       "      <td>R-HSA-166663</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009529</td>\n",
       "      <td>0.006807</td>\n",
       "      <td>0.007827</td>\n",
       "      <td>0.013952</td>\n",
       "      <td>0.009529</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.002382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0M8Q6</td>\n",
       "      <td>R-HSA-198933</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.001778</td>\n",
       "      <td>0.011938</td>\n",
       "      <td>0.005106</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.004229</td>\n",
       "      <td>0.001569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0M8Q6</td>\n",
       "      <td>R-HSA-198933</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009529</td>\n",
       "      <td>0.006807</td>\n",
       "      <td>0.007827</td>\n",
       "      <td>0.013952</td>\n",
       "      <td>0.009529</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.002382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0M8Q6</td>\n",
       "      <td>R-HSA-2029481</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.001778</td>\n",
       "      <td>0.011938</td>\n",
       "      <td>0.005106</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.004229</td>\n",
       "      <td>0.001569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7079</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>R-HSA-9612973</td>\n",
       "      <td>output_node</td>\n",
       "      <td>1</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.187380</td>\n",
       "      <td>0.052540</td>\n",
       "      <td>0.150081</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.056850</td>\n",
       "      <td>0.055988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7080</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>R-HSA-9709957</td>\n",
       "      <td>output_node</td>\n",
       "      <td>0</td>\n",
       "      <td>0.211574</td>\n",
       "      <td>0.198006</td>\n",
       "      <td>0.219232</td>\n",
       "      <td>0.217486</td>\n",
       "      <td>0.211574</td>\n",
       "      <td>0.009621</td>\n",
       "      <td>0.105787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7081</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>R-HSA-9709957</td>\n",
       "      <td>output_node</td>\n",
       "      <td>1</td>\n",
       "      <td>0.052519</td>\n",
       "      <td>0.041629</td>\n",
       "      <td>0.059777</td>\n",
       "      <td>0.056152</td>\n",
       "      <td>0.052519</td>\n",
       "      <td>0.007842</td>\n",
       "      <td>0.026259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7082</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>R-HSA-9748784</td>\n",
       "      <td>output_node</td>\n",
       "      <td>0</td>\n",
       "      <td>0.164754</td>\n",
       "      <td>0.222715</td>\n",
       "      <td>0.025688</td>\n",
       "      <td>0.245859</td>\n",
       "      <td>0.164754</td>\n",
       "      <td>0.098787</td>\n",
       "      <td>0.054918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7083</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>R-HSA-9748784</td>\n",
       "      <td>output_node</td>\n",
       "      <td>1</td>\n",
       "      <td>0.061606</td>\n",
       "      <td>0.013422</td>\n",
       "      <td>0.066391</td>\n",
       "      <td>0.105004</td>\n",
       "      <td>0.061606</td>\n",
       "      <td>0.037541</td>\n",
       "      <td>0.020535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7084 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      source_layer  target_layer    source_node    target_node  class_idx  \\\n",
       "0                0             1         A0M8Q6   R-HSA-166663          0   \n",
       "1                0             1         A0M8Q6   R-HSA-166663          1   \n",
       "2                0             1         A0M8Q6   R-HSA-198933          0   \n",
       "3                0             1         A0M8Q6   R-HSA-198933          1   \n",
       "4                0             1         A0M8Q6  R-HSA-2029481          0   \n",
       "...            ...           ...            ...            ...        ...   \n",
       "7079             4             5  R-HSA-9612973    output_node          1   \n",
       "7080             4             5  R-HSA-9709957    output_node          0   \n",
       "7081             4             5  R-HSA-9709957    output_node          1   \n",
       "7082             4             5  R-HSA-9748784    output_node          0   \n",
       "7083             4             5  R-HSA-9748784    output_node          1   \n",
       "\n",
       "      importance  importance_0  importance_1  importance_2  importance_mean  \\\n",
       "0       0.006274      0.001778      0.011938      0.005106         0.006274   \n",
       "1       0.009529      0.006807      0.007827      0.013952         0.009529   \n",
       "2       0.006274      0.001778      0.011938      0.005106         0.006274   \n",
       "3       0.009529      0.006807      0.007827      0.013952         0.009529   \n",
       "4       0.006274      0.001778      0.011938      0.005106         0.006274   \n",
       "...          ...           ...           ...           ...              ...   \n",
       "7079    0.130000      0.187380      0.052540      0.150081         0.130000   \n",
       "7080    0.211574      0.198006      0.219232      0.217486         0.211574   \n",
       "7081    0.052519      0.041629      0.059777      0.056152         0.052519   \n",
       "7082    0.164754      0.222715      0.025688      0.245859         0.164754   \n",
       "7083    0.061606      0.013422      0.066391      0.105004         0.061606   \n",
       "\n",
       "      importance_std  normalized_importance  \n",
       "0           0.004229               0.001569  \n",
       "1           0.003156               0.002382  \n",
       "2           0.004229               0.001569  \n",
       "3           0.003156               0.002382  \n",
       "4           0.004229               0.001569  \n",
       "...              ...                    ...  \n",
       "7079        0.056850               0.055988  \n",
       "7080        0.009621               0.105787  \n",
       "7081        0.007842               0.026259  \n",
       "7082        0.098787               0.054918  \n",
       "7083        0.037541               0.020535  \n",
       "\n",
       "[7084 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_average_explanations = explainer.normalize_importances(average_explanations, method=\"fan\")\n",
    "normalized_average_explanations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
