{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] BINN is on device: cpu\n",
      "Mapping group labels: {np.int64(1): 0, np.int64(2): 1}\n",
      "[Epoch 1/50] Train Loss: 0.8969, Train Accuracy: 0.4791\n",
      "[Epoch 1/50] Val Loss: 0.6932, Val Accuracy: 0.4688\n",
      "[Epoch 2/50] Train Loss: 0.9213, Train Accuracy: 0.4909\n",
      "[Epoch 2/50] Val Loss: 0.6933, Val Accuracy: 0.4688\n",
      "[Epoch 3/50] Train Loss: 0.8488, Train Accuracy: 0.5341\n",
      "[Epoch 3/50] Val Loss: 0.6934, Val Accuracy: 0.4688\n",
      "[Epoch 4/50] Train Loss: 0.9623, Train Accuracy: 0.4134\n",
      "[Epoch 4/50] Val Loss: 0.6938, Val Accuracy: 0.4688\n",
      "[Epoch 5/50] Train Loss: 0.8799, Train Accuracy: 0.5386\n",
      "[Epoch 5/50] Val Loss: 0.6940, Val Accuracy: 0.4688\n",
      "[Epoch 6/50] Train Loss: 0.7955, Train Accuracy: 0.5416\n",
      "[Epoch 6/50] Val Loss: 0.6942, Val Accuracy: 0.4688\n",
      "[Epoch 7/50] Train Loss: 0.8800, Train Accuracy: 0.5353\n",
      "[Epoch 7/50] Val Loss: 0.6946, Val Accuracy: 0.4688\n",
      "[Epoch 8/50] Train Loss: 0.6925, Train Accuracy: 0.6297\n",
      "[Epoch 8/50] Val Loss: 0.6945, Val Accuracy: 0.4688\n",
      "[Epoch 9/50] Train Loss: 0.7421, Train Accuracy: 0.5929\n",
      "[Epoch 9/50] Val Loss: 0.6892, Val Accuracy: 0.5312\n",
      "[Epoch 10/50] Train Loss: 0.7883, Train Accuracy: 0.5366\n",
      "[Epoch 10/50] Val Loss: 0.6832, Val Accuracy: 0.5469\n",
      "[Epoch 11/50] Train Loss: 0.7489, Train Accuracy: 0.5647\n",
      "[Epoch 11/50] Val Loss: 0.6800, Val Accuracy: 0.5469\n",
      "[Epoch 12/50] Train Loss: 0.8042, Train Accuracy: 0.5629\n",
      "[Epoch 12/50] Val Loss: 0.6717, Val Accuracy: 0.6250\n",
      "[Epoch 13/50] Train Loss: 0.7362, Train Accuracy: 0.5591\n",
      "[Epoch 13/50] Val Loss: 0.6542, Val Accuracy: 0.6250\n",
      "[Epoch 14/50] Train Loss: 0.7101, Train Accuracy: 0.6373\n",
      "[Epoch 14/50] Val Loss: 0.6367, Val Accuracy: 0.6250\n",
      "[Epoch 15/50] Train Loss: 0.6827, Train Accuracy: 0.6597\n",
      "[Epoch 15/50] Val Loss: 0.6016, Val Accuracy: 0.6250\n",
      "[Epoch 16/50] Train Loss: 0.7291, Train Accuracy: 0.6159\n",
      "[Epoch 16/50] Val Loss: 0.5811, Val Accuracy: 0.7031\n",
      "[Epoch 17/50] Train Loss: 0.7105, Train Accuracy: 0.6179\n",
      "[Epoch 17/50] Val Loss: 0.5614, Val Accuracy: 0.7656\n",
      "[Epoch 18/50] Train Loss: 0.6666, Train Accuracy: 0.6054\n",
      "[Epoch 18/50] Val Loss: 0.5369, Val Accuracy: 0.7969\n",
      "[Epoch 19/50] Train Loss: 0.7046, Train Accuracy: 0.5991\n",
      "[Epoch 19/50] Val Loss: 0.5128, Val Accuracy: 0.7969\n",
      "[Epoch 20/50] Train Loss: 0.6247, Train Accuracy: 0.6248\n",
      "[Epoch 20/50] Val Loss: 0.4943, Val Accuracy: 0.8125\n",
      "[Epoch 21/50] Train Loss: 0.6083, Train Accuracy: 0.6767\n",
      "[Epoch 21/50] Val Loss: 0.4757, Val Accuracy: 0.8281\n",
      "[Epoch 22/50] Train Loss: 0.6025, Train Accuracy: 0.6886\n",
      "[Epoch 22/50] Val Loss: 0.4639, Val Accuracy: 0.8281\n",
      "[Epoch 23/50] Train Loss: 0.6644, Train Accuracy: 0.6442\n",
      "[Epoch 23/50] Val Loss: 0.4515, Val Accuracy: 0.8281\n",
      "[Epoch 24/50] Train Loss: 0.5855, Train Accuracy: 0.7004\n",
      "[Epoch 24/50] Val Loss: 0.4487, Val Accuracy: 0.8438\n",
      "[Epoch 25/50] Train Loss: 0.6587, Train Accuracy: 0.5897\n",
      "[Epoch 25/50] Val Loss: 0.4746, Val Accuracy: 0.8438\n",
      "[Epoch 26/50] Train Loss: 0.5908, Train Accuracy: 0.6754\n",
      "[Epoch 26/50] Val Loss: 0.4761, Val Accuracy: 0.8438\n",
      "[Epoch 27/50] Train Loss: 0.5355, Train Accuracy: 0.7317\n",
      "[Epoch 27/50] Val Loss: 0.4581, Val Accuracy: 0.8438\n",
      "[Epoch 28/50] Train Loss: 0.5655, Train Accuracy: 0.6892\n",
      "[Epoch 28/50] Val Loss: 0.4375, Val Accuracy: 0.8594\n",
      "[Epoch 29/50] Train Loss: 0.5315, Train Accuracy: 0.7317\n",
      "[Epoch 29/50] Val Loss: 0.4290, Val Accuracy: 0.8594\n",
      "[Epoch 30/50] Train Loss: 0.5764, Train Accuracy: 0.6616\n",
      "[Epoch 30/50] Val Loss: 0.4459, Val Accuracy: 0.8750\n",
      "[Epoch 31/50] Train Loss: 0.4985, Train Accuracy: 0.7280\n",
      "[Epoch 31/50] Val Loss: 0.4554, Val Accuracy: 0.8750\n",
      "[Epoch 32/50] Train Loss: 0.5587, Train Accuracy: 0.7211\n",
      "[Epoch 32/50] Val Loss: 0.4329, Val Accuracy: 0.8750\n",
      "[Epoch 33/50] Train Loss: 0.5369, Train Accuracy: 0.7254\n",
      "[Epoch 33/50] Val Loss: 0.4142, Val Accuracy: 0.8750\n",
      "[Epoch 34/50] Train Loss: 0.5320, Train Accuracy: 0.7580\n",
      "[Epoch 34/50] Val Loss: 0.3840, Val Accuracy: 0.8750\n",
      "[Epoch 35/50] Train Loss: 0.4860, Train Accuracy: 0.7530\n",
      "[Epoch 35/50] Val Loss: 0.3700, Val Accuracy: 0.8750\n",
      "[Epoch 36/50] Train Loss: 0.4623, Train Accuracy: 0.8011\n",
      "[Epoch 36/50] Val Loss: 0.3728, Val Accuracy: 0.8750\n",
      "[Epoch 37/50] Train Loss: 0.4974, Train Accuracy: 0.7481\n",
      "[Epoch 37/50] Val Loss: 0.3770, Val Accuracy: 0.8750\n",
      "[Epoch 38/50] Train Loss: 0.4804, Train Accuracy: 0.7843\n",
      "[Epoch 38/50] Val Loss: 0.3635, Val Accuracy: 0.8750\n",
      "[Epoch 39/50] Train Loss: 0.4868, Train Accuracy: 0.7461\n",
      "[Epoch 39/50] Val Loss: 0.3565, Val Accuracy: 0.8750\n",
      "[Epoch 40/50] Train Loss: 0.5145, Train Accuracy: 0.7649\n",
      "[Epoch 40/50] Val Loss: 0.3469, Val Accuracy: 0.8750\n",
      "[Epoch 41/50] Train Loss: 0.4912, Train Accuracy: 0.7567\n",
      "[Epoch 41/50] Val Loss: 0.3534, Val Accuracy: 0.8750\n",
      "[Epoch 42/50] Train Loss: 0.5764, Train Accuracy: 0.6830\n",
      "[Epoch 42/50] Val Loss: 0.3473, Val Accuracy: 0.8750\n",
      "[Epoch 43/50] Train Loss: 0.4658, Train Accuracy: 0.8142\n",
      "[Epoch 43/50] Val Loss: 0.3539, Val Accuracy: 0.8750\n",
      "[Epoch 44/50] Train Loss: 0.4501, Train Accuracy: 0.7912\n",
      "[Epoch 44/50] Val Loss: 0.3532, Val Accuracy: 0.8750\n",
      "[Epoch 45/50] Train Loss: 0.4823, Train Accuracy: 0.7731\n",
      "[Epoch 45/50] Val Loss: 0.3443, Val Accuracy: 0.8750\n",
      "[Epoch 46/50] Train Loss: 0.4722, Train Accuracy: 0.7461\n",
      "[Epoch 46/50] Val Loss: 0.3270, Val Accuracy: 0.8906\n",
      "[Epoch 47/50] Train Loss: 0.4765, Train Accuracy: 0.7642\n",
      "[Epoch 47/50] Val Loss: 0.3152, Val Accuracy: 0.8906\n",
      "[Epoch 48/50] Train Loss: 0.4389, Train Accuracy: 0.7856\n",
      "[Epoch 48/50] Val Loss: 0.3169, Val Accuracy: 0.8906\n",
      "[Epoch 49/50] Train Loss: 0.4554, Train Accuracy: 0.7823\n",
      "[Epoch 49/50] Val Loss: 0.3083, Val Accuracy: 0.8906\n",
      "[Epoch 50/50] Train Loss: 0.4506, Train Accuracy: 0.7705\n",
      "[Epoch 50/50] Val Loss: 0.3137, Val Accuracy: 0.8906\n"
     ]
    }
   ],
   "source": [
    "from binn import BINN, BINNDataLoader, BINNTrainer\n",
    "import pandas as pd\n",
    "\n",
    "# Load your data\n",
    "data_matrix = pd.read_csv(\"../data/test_qm.csv\")\n",
    "design_matrix = pd.read_csv(\"../data/design_matrix.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Initialize BINN\n",
    "binn = BINN(data_matrix=data_matrix, network_source=\"reactome\", n_layers=4, dropout=0.2)\n",
    "\n",
    "## Initialize DataLoader\n",
    "binn_dataloader = BINNDataLoader(binn)\n",
    "\n",
    "# Create DataLoaders\n",
    "dataloaders = binn_dataloader.create_dataloaders(\n",
    "    data_matrix=data_matrix,\n",
    "    design_matrix=design_matrix,\n",
    "    feature_column=\"Protein\",\n",
    "    group_column=\"group\",\n",
    "    sample_column=\"sample\",\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "# Train the model\n",
    "trainer = BINNTrainer(binn)\n",
    "trainer.fit(dataloaders=dataloaders, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_layer</th>\n",
       "      <th>target_layer</th>\n",
       "      <th>source_node</th>\n",
       "      <th>target_node</th>\n",
       "      <th>class_idx</th>\n",
       "      <th>importance</th>\n",
       "      <th>source_id</th>\n",
       "      <th>target_id</th>\n",
       "      <th>normalized_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0M8Q6</td>\n",
       "      <td>R-HSA-166663</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017386</td>\n",
       "      <td>nA0M8Q6_l0</td>\n",
       "      <td>nR-HSA-166663_l1</td>\n",
       "      <td>0.004346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0M8Q6</td>\n",
       "      <td>R-HSA-166663</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024437</td>\n",
       "      <td>nA0M8Q6_l0</td>\n",
       "      <td>nR-HSA-166663_l1</td>\n",
       "      <td>0.006109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0M8Q6</td>\n",
       "      <td>R-HSA-198933</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017386</td>\n",
       "      <td>nA0M8Q6_l0</td>\n",
       "      <td>nR-HSA-198933_l1</td>\n",
       "      <td>0.004346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0M8Q6</td>\n",
       "      <td>R-HSA-198933</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024437</td>\n",
       "      <td>nA0M8Q6_l0</td>\n",
       "      <td>nR-HSA-198933_l1</td>\n",
       "      <td>0.006109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0M8Q6</td>\n",
       "      <td>R-HSA-2029481</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017386</td>\n",
       "      <td>nA0M8Q6_l0</td>\n",
       "      <td>nR-HSA-2029481_l1</td>\n",
       "      <td>0.004346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7079</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>R-HSA-9612973</td>\n",
       "      <td>output_node</td>\n",
       "      <td>1</td>\n",
       "      <td>0.074729</td>\n",
       "      <td>nR-HSA-9612973_l4</td>\n",
       "      <td>noutput_node_l5</td>\n",
       "      <td>0.032184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7080</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>R-HSA-9709957</td>\n",
       "      <td>output_node</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115902</td>\n",
       "      <td>nR-HSA-9709957_l4</td>\n",
       "      <td>noutput_node_l5</td>\n",
       "      <td>0.057951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7081</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>R-HSA-9709957</td>\n",
       "      <td>output_node</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>nR-HSA-9709957_l4</td>\n",
       "      <td>noutput_node_l5</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7082</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>R-HSA-9748784</td>\n",
       "      <td>output_node</td>\n",
       "      <td>0</td>\n",
       "      <td>0.206383</td>\n",
       "      <td>nR-HSA-9748784_l4</td>\n",
       "      <td>noutput_node_l5</td>\n",
       "      <td>0.068794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7083</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>R-HSA-9748784</td>\n",
       "      <td>output_node</td>\n",
       "      <td>1</td>\n",
       "      <td>0.151396</td>\n",
       "      <td>nR-HSA-9748784_l4</td>\n",
       "      <td>noutput_node_l5</td>\n",
       "      <td>0.050465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7084 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      source_layer  target_layer    source_node    target_node  class_idx  \\\n",
       "0                0             1         A0M8Q6   R-HSA-166663          0   \n",
       "1                0             1         A0M8Q6   R-HSA-166663          1   \n",
       "2                0             1         A0M8Q6   R-HSA-198933          0   \n",
       "3                0             1         A0M8Q6   R-HSA-198933          1   \n",
       "4                0             1         A0M8Q6  R-HSA-2029481          0   \n",
       "...            ...           ...            ...            ...        ...   \n",
       "7079             4             5  R-HSA-9612973    output_node          1   \n",
       "7080             4             5  R-HSA-9709957    output_node          0   \n",
       "7081             4             5  R-HSA-9709957    output_node          1   \n",
       "7082             4             5  R-HSA-9748784    output_node          0   \n",
       "7083             4             5  R-HSA-9748784    output_node          1   \n",
       "\n",
       "      importance          source_id          target_id  normalized_importance  \n",
       "0       0.017386         nA0M8Q6_l0   nR-HSA-166663_l1               0.004346  \n",
       "1       0.024437         nA0M8Q6_l0   nR-HSA-166663_l1               0.006109  \n",
       "2       0.017386         nA0M8Q6_l0   nR-HSA-198933_l1               0.004346  \n",
       "3       0.024437         nA0M8Q6_l0   nR-HSA-198933_l1               0.006109  \n",
       "4       0.017386         nA0M8Q6_l0  nR-HSA-2029481_l1               0.004346  \n",
       "...          ...                ...                ...                    ...  \n",
       "7079    0.074729  nR-HSA-9612973_l4    noutput_node_l5               0.032184  \n",
       "7080    0.115902  nR-HSA-9709957_l4    noutput_node_l5               0.057951  \n",
       "7081    0.000118  nR-HSA-9709957_l4    noutput_node_l5               0.000059  \n",
       "7082    0.206383  nR-HSA-9748784_l4    noutput_node_l5               0.068794  \n",
       "7083    0.151396  nR-HSA-9748784_l4    noutput_node_l5               0.050465  \n",
       "\n",
       "[7084 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from binn import BINNExplainer\n",
    "\n",
    "explainer = BINNExplainer(binn)\n",
    "single_explanations = explainer.explain_single(dataloaders, split=\"val\")\n",
    "normalized_single_explanations = explainer.normalize_importances(single_explanations, method=\"fan\")\n",
    "normalized_single_explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "arrangement": "snap",
         "link": {
          "color": [
           "rgba(150, 183, 255, 0.75)",
           "rgba(241, 204, 184, 0.75)",
           "rgba(212, 219, 230, 0.75)",
           "rgba(162, 193, 255, 0.75)",
           "rgba(162, 193, 255, 0.75)",
           "rgba(162, 193, 255, 0.75)",
           "rgba(162, 193, 255, 0.75)",
           "rgba(162, 193, 255, 0.75)",
           "rgba(73, 97, 210, 0.75)",
           "rgba(247, 169, 139, 0.75)",
           "rgba(180, 4, 38, 0.75)",
           "rgba(224, 101, 79, 0.75)",
           "rgba(236, 211, 197, 0.75)",
           "rgba(180, 4, 38, 0.75)",
           "rgba(180, 4, 38, 0.75)",
           "rgba(106, 139, 239, 0.75)",
           "rgba(195, 213, 244, 0.75)",
           "rgba(180, 4, 38, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(236, 211, 197, 0.75)",
           "rgba(102, 135, 237, 0.75)",
           "rgba(213, 219, 229, 0.75)",
           "rgba(137, 172, 253, 0.75)",
           "rgba(182, 206, 250, 0.75)",
           "rgba(88, 117, 225, 0.75)",
           "rgba(88, 117, 225, 0.75)",
           "rgba(180, 4, 38, 0.75)",
           "rgba(62, 81, 197, 0.75)",
           "rgba(62, 81, 197, 0.75)",
           "rgba(121, 156, 248, 0.75)",
           "rgba(217, 220, 225, 0.75)",
           "rgba(228, 110, 86, 0.75)",
           "rgba(196, 48, 50, 0.75)",
           "rgba(180, 4, 38, 0.75)",
           "rgba(152, 185, 255, 0.75)",
           "rgba(182, 206, 250, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(210, 75, 64, 0.75)",
           "rgba(192, 212, 245, 0.75)",
           "rgba(114, 149, 244, 0.75)",
           "rgba(188, 210, 247, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(247, 175, 145, 0.75)",
           "rgba(177, 203, 252, 0.75)",
           "rgba(245, 196, 172, 0.75)",
           "rgba(245, 196, 172, 0.75)",
           "rgba(245, 196, 172, 0.75)",
           "rgba(245, 196, 172, 0.75)",
           "rgba(245, 196, 172, 0.75)",
           "rgba(144, 178, 254, 0.75)",
           "rgba(247, 185, 158, 0.75)",
           "rgba(103, 136, 238, 0.75)",
           "rgba(132, 167, 252, 0.75)",
           "rgba(139, 173, 253, 0.75)",
           "rgba(195, 213, 244, 0.75)",
           "rgba(195, 213, 244, 0.75)",
           "rgba(195, 213, 244, 0.75)",
           "rgba(195, 213, 244, 0.75)",
           "rgba(195, 213, 244, 0.75)",
           "rgba(104, 138, 239, 0.75)",
           "rgba(167, 197, 254, 0.75)",
           "rgba(167, 197, 254, 0.75)",
           "rgba(228, 110, 86, 0.75)",
           "rgba(243, 200, 178, 0.75)",
           "rgba(188, 210, 247, 0.75)",
           "rgba(199, 215, 240, 0.75)",
           "rgba(198, 214, 241, 0.75)",
           "rgba(246, 163, 133, 0.75)",
           "rgba(231, 215, 206, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(236,236,236, 0.75)"
          ],
          "source": [
           5,
           37,
           39,
           39,
           39,
           39,
           39,
           21,
           21,
           47,
           47,
           19,
           19,
           4,
           9,
           9,
           45,
           45,
           45,
           45,
           45,
           3,
           3,
           3,
           3,
           3,
           14,
           27,
           28,
           29,
           7,
           22,
           34,
           33,
           32,
           0,
           50,
           12,
           8,
           53,
           15,
           46,
           23,
           54,
           51,
           38,
           42,
           16,
           40,
           26,
           20,
           17,
           18,
           1,
           10,
           41,
           43,
           48,
           24,
           11,
           35,
           2,
           49,
           6,
           44,
           52,
           13,
           13,
           13,
           13,
           13,
           36,
           36,
           36,
           36,
           36,
           36,
           36,
           36,
           36,
           36,
           30,
           31,
           31,
           31,
           31,
           31,
           55,
           55,
           55
          ],
          "target": [
           55,
           55,
           55,
           20,
           17,
           18,
           10,
           55,
           1,
           55,
           41,
           55,
           26,
           55,
           55,
           10,
           55,
           20,
           17,
           18,
           10,
           55,
           20,
           17,
           18,
           10,
           36,
           54,
           36,
           53,
           53,
           15,
           36,
           46,
           23,
           12,
           2,
           30,
           35,
           48,
           30,
           11,
           49,
           6,
           44,
           52,
           31,
           29,
           31,
           7,
           32,
           31,
           31,
           27,
           27,
           14,
           25,
           25,
           25,
           25,
           25,
           25,
           25,
           25,
           25,
           25,
           55,
           10,
           16,
           42,
           40,
           30,
           43,
           11,
           44,
           6,
           52,
           48,
           35,
           24,
           49,
           25,
           36,
           12,
           53,
           15,
           46,
           31,
           27,
           7
          ],
          "value": [
           0.0613467425650624,
           0.060318037524050884,
           0.24786204299130515,
           0.006522685341876451,
           0.006522685341876451,
           0.006522685341876451,
           0.006522685341876451,
           0.006771374619071395,
           0.0033856873095356975,
           0.057146139559652434,
           0.003571633722478277,
           0.018799812445308088,
           0.004699953111327022,
           0.008073170699487011,
           0.16658920202958866,
           0.003544451107012525,
           0.17035525184484876,
           0.003961750042903459,
           0.003961750042903459,
           0.003961750042903459,
           0.003961750042903459,
           0.13265664702707225,
           0.0032355279762700546,
           0.0032355279762700546,
           0.0032355279762700546,
           0.0032355279762700546,
           0.10520133749806432,
           0.14141250216447612,
           0.0816302254153363,
           0.08885323582125426,
           0.13026956468042414,
           0.07401700546351746,
           0.07240049907710906,
           0.09120096669853799,
           0.13418079350784995,
           0.08083386967343038,
           0.09131842020040373,
           0.15043683655568585,
           0.10836440617278556,
           0.12397776996914843,
           0.06752100137771692,
           0.06812088922056263,
           0.10077769192825108,
           0.1062091241211312,
           0.09503499330074462,
           0.08823886715357009,
           0.0674279658025312,
           0.09870977700990986,
           0.07847220611139426,
           0.14472043100211732,
           0.1490655337687751,
           0.07674148234537063,
           0.08903518695709552,
           0.11055326308588584,
           0.06840276296839508,
           0.11687139094852518,
           0.077564896637063,
           0.12098788315623801,
           0.12086683748963836,
           0.09040697042914023,
           0.08903858031499243,
           0.09462704663561176,
           0.10458513192370397,
           0.13164914640582304,
           0.07895057944037974,
           0.09132292756740942,
           0.09832793934804195,
           0.0008367894696795982,
           0.00045148491088758676,
           0.0001656927717655942,
           0.0002180934996252909,
           0.06335631846834001,
           0.010794088339415092,
           0.0011883113098232804,
           0.001975934678495721,
           0.0044411360498576484,
           0.003175825696358862,
           0.0004953747931383562,
           0.0030769582038927728,
           0.009408713254648959,
           0.002087339206029285,
           0.1,
           0.0965087415698843,
           0.001582505721224663,
           0.000581367087020466,
           0.0006338422231897693,
           0.00069354339868081,
           0.09447074342563401,
           0.0055292565743660016,
           0
          ]
         },
         "node": {
          "color": [
           "rgba(252, 179, 152, 0.75)",
           "rgba(242, 70, 51, 0.75)",
           "rgba(251, 117, 85, 0.75)",
           "rgba(252, 167, 139, 0.75)",
           "rgba(255, 237, 229, 0.75)",
           "rgba(215, 35, 34, 0.75)",
           "rgba(103, 0, 13, 0.75)",
           "rgba(168, 16, 22, 0.75)",
           "rgba(245, 82, 58, 0.75)",
           "rgba(103, 0, 13, 0.75)",
           "rgba(254, 217, 201, 0.75)",
           "rgba(252, 135, 103, 0.75)",
           "rgba(103, 0, 13, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(245, 82, 58, 0.75)",
           "rgba(254, 220, 205, 0.75)",
           "rgba(251, 115, 83, 0.75)",
           "rgba(252, 190, 165, 0.75)",
           "rgba(252, 148, 116, 0.75)",
           "rgba(254, 229, 217, 0.75)",
           "rgba(103, 0, 13, 0.75)",
           "rgba(255, 243, 237, 0.75)",
           "rgba(253, 204, 184, 0.75)",
           "rgba(251, 110, 78, 0.75)",
           "rgba(173, 17, 23, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(124, 5, 16, 0.75)",
           "rgba(103, 0, 13, 0.75)",
           "rgba(252, 176, 149, 0.75)",
           "rgba(252, 148, 116, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(146, 10, 19, 0.75)",
           "rgba(252, 138, 106, 0.75)",
           "rgba(253, 210, 191, 0.75)",
           "rgba(252, 142, 110, 0.75)",
           "rgba(236,236,236, 0.75)",
           "rgba(219, 40, 36, 0.75)",
           "rgba(252, 153, 122, 0.75)",
           "rgba(238, 58, 44, 0.75)",
           "rgba(252, 184, 158, 0.75)",
           "rgba(228, 48, 39, 0.75)",
           "rgba(254, 219, 204, 0.75)",
           "rgba(252, 195, 171, 0.75)",
           "rgba(252, 189, 164, 0.75)",
           "rgba(252, 135, 103, 0.75)",
           "rgba(254, 218, 202, 0.75)",
           "rgba(252, 162, 133, 0.75)",
           "rgba(173, 17, 23, 0.75)",
           "rgba(240, 64, 47, 0.75)",
           "rgba(252, 142, 110, 0.75)",
           "rgba(252, 130, 98, 0.75)",
           "rgba(252, 132, 100, 0.75)",
           "rgba(210, 31, 32, 0.75)",
           "rgba(247, 91, 64, 0.75)",
           "rgba(236,236,236, 0.75)"
          ],
          "label": [
           "R-HSA-912446",
           "R-HSA-8853884",
           "R-HSA-400253",
           "Q96A08",
           "P27169",
           "P02452",
           "R-HSA-74160",
           "R-HSA-446353",
           "R-HSA-390522",
           "P28072",
           "R-HSA-8878171",
           "R-HSA-1852241",
           "R-HSA-1500620",
           "Other connections 1",
           "R-HSA-112310",
           "R-HSA-450531",
           "R-HSA-418990",
           "R-HSA-73927",
           "R-HSA-73928",
           "P12814",
           "R-HSA-68616",
           "P07333",
           "R-HSA-450408",
           "R-HSA-69002",
           "R-HSA-1643685",
           "Other connections 6",
           "R-HSA-446388",
           "R-HSA-212436",
           "R-HSA-2534343",
           "R-HSA-421270",
           "Other connections 5",
           "Other connections 3",
           "R-HSA-68867",
           "R-HSA-5620912",
           "R-HSA-5578749",
           "R-HSA-397014",
           "Other connections 4",
           "P04114",
           "R-HSA-9754706",
           "P04908",
           "R-HSA-442755",
           "R-HSA-888590",
           "R-HSA-140534",
           "R-HSA-1430728",
           "R-HSA-9612973",
           "P62805",
           "R-HSA-5617833",
           "P11142",
           "R-HSA-1500931",
           "R-HSA-69306",
           "R-HSA-1368108",
           "R-HSA-9613829",
           "R-HSA-9748784",
           "R-HSA-446728",
           "R-HSA-73857",
           "Other connections 2"
          ],
          "line": {
           "color": "white",
           "width": 0
          },
          "pad": 15,
          "thickness": 15,
          "x": [
           [
            0.33499999999999996
           ],
           [
            0.16833333333333333
           ],
           [
            0.6683333333333333
           ],
           [
            0.0016666666666666668
           ],
           [
            0.0016666666666666668
           ],
           [
            0.0016666666666666668
           ],
           [
            0.6683333333333333
           ],
           [
            0.33499999999999996
           ],
           [
            0.5016666666666666
           ],
           [
            0.0016666666666666668
           ],
           [
            0.16833333333333333
           ],
           [
            0.6683333333333333
           ],
           [
            0.5016666666666666
           ],
           [
            0.16833333333333333
           ],
           [
            0.33499999999999996
           ],
           [
            0.5016666666666666
           ],
           [
            0.16833333333333333
           ],
           [
            0.16833333333333333
           ],
           [
            0.16833333333333333
           ],
           [
            0.0016666666666666668
           ],
           [
            0.16833333333333333
           ],
           [
            0.0016666666666666668
           ],
           [
            0.33499999999999996
           ],
           [
            0.5016666666666666
           ],
           [
            0.6683333333333333
           ],
           [
            0.5
           ],
           [
            0.16833333333333333
           ],
           [
            0.33499999999999996
           ],
           [
            0.33499999999999996
           ],
           [
            0.33499999999999996
           ],
           [
            0.5
           ],
           [
            0.5016666666666666
           ],
           [
            0.33499999999999996
           ],
           [
            0.33499999999999996
           ],
           [
            0.33499999999999996
           ],
           [
            0.6683333333333333
           ],
           [
            0.6683333333333333
           ],
           [
            0.0016666666666666668
           ],
           [
            0.5016666666666666
           ],
           [
            0.0016666666666666668
           ],
           [
            0.16833333333333333
           ],
           [
            0.16833333333333333
           ],
           [
            0.16833333333333333
           ],
           [
            0.6683333333333333
           ],
           [
            0.6683333333333333
           ],
           [
            0.0016666666666666668
           ],
           [
            0.5016666666666666
           ],
           [
            0.0016666666666666668
           ],
           [
            0.6683333333333333
           ],
           [
            0.6683333333333333
           ],
           [
            0.5016666666666666
           ],
           [
            0.5016666666666666
           ],
           [
            0.6683333333333333
           ],
           [
            0.5016666666666666
           ],
           [
            0.5016666666666666
           ],
           [
            0.33499999999999996
           ]
          ],
          "y": [
           [
            0.6221530941006556
           ],
           [
            0.2666370403288524
           ],
           [
            0.3555160537718032
           ],
           [
            0.5332740806577048
           ],
           [
            0.7110321075436064
           ],
           [
            0.0888790134429508
           ],
           [
            0
           ],
           [
            0.1777580268859016
           ],
           [
            0.1777580268859016
           ],
           [
            0
           ],
           [
            0.7110321075436064
           ],
           [
            0.5332740806577048
           ],
           [
            0
           ],
           [
            0.9
           ],
           [
            0.2666370403288524
           ],
           [
            0.7999111209865571
           ],
           [
            0.3555160537718032
           ],
           [
            0.6221530941006556
           ],
           [
            0.44439506721475397
           ],
           [
            0.6221530941006556
           ],
           [
            0
           ],
           [
            0.7999111209865571
           ],
           [
            0.7110321075436064
           ],
           [
            0.3555160537718032
           ],
           [
            0.1777580268859016
           ],
           [
            0.5
           ],
           [
            0.0888790134429508
           ],
           [
            0
           ],
           [
            0.5332740806577048
           ],
           [
            0.44439506721475397
           ],
           [
            0.5
           ],
           [
            0.9
           ],
           [
            0.0888790134429508
           ],
           [
            0.3555160537718032
           ],
           [
            0.7999111209865571
           ],
           [
            0.6221530941006556
           ],
           [
            0.9
           ],
           [
            0.1777580268859016
           ],
           [
            0.6221530941006556
           ],
           [
            0.2666370403288524
           ],
           [
            0.5332740806577048
           ],
           [
            0.1777580268859016
           ],
           [
            0.7999111209865571
           ],
           [
            0.7999111209865571
           ],
           [
            0.7110321075436064
           ],
           [
            0.3555160537718032
           ],
           [
            0.7110321075436064
           ],
           [
            0.44439506721475397
           ],
           [
            0.0888790134429508
           ],
           [
            0.2666370403288524
           ],
           [
            0.5332740806577048
           ],
           [
            0.44439506721475397
           ],
           [
            0.44439506721475397
           ],
           [
            0.0888790134429508
           ],
           [
            0.2666370403288524
           ],
           [
            0.9
           ]
          ]
         },
         "orientation": "h",
         "textfont": {
          "family": "Arial",
          "size": 15
         },
         "type": "sankey"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from binn.plot.sankey import plot_sankey\n",
    "\n",
    "plot_sankey(single_explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BINNExplainer] Iteration 1/3...\n",
      "[Epoch 1/50] Train Loss: 0.6609, Train Accuracy: 0.6261\n",
      "[Epoch 1/50] Val Loss: 0.6929, Val Accuracy: 0.5312\n",
      "[Epoch 2/50] Train Loss: 0.7479, Train Accuracy: 0.5498\n",
      "[Epoch 2/50] Val Loss: 0.6927, Val Accuracy: 0.5312\n",
      "[Epoch 3/50] Train Loss: 0.7175, Train Accuracy: 0.5985\n",
      "[Epoch 3/50] Val Loss: 0.6926, Val Accuracy: 0.5312\n",
      "[Epoch 4/50] Train Loss: 0.6994, Train Accuracy: 0.6179\n",
      "[Epoch 4/50] Val Loss: 0.6920, Val Accuracy: 0.5312\n",
      "[Epoch 5/50] Train Loss: 0.7394, Train Accuracy: 0.6347\n",
      "[Epoch 5/50] Val Loss: 0.6905, Val Accuracy: 0.5312\n",
      "[Epoch 6/50] Train Loss: 0.6687, Train Accuracy: 0.6291\n",
      "[Epoch 6/50] Val Loss: 0.6872, Val Accuracy: 0.5312\n",
      "[Epoch 7/50] Train Loss: 0.6867, Train Accuracy: 0.6179\n",
      "[Epoch 7/50] Val Loss: 0.6802, Val Accuracy: 0.5312\n",
      "[Epoch 8/50] Train Loss: 0.6190, Train Accuracy: 0.6491\n",
      "[Epoch 8/50] Val Loss: 0.6657, Val Accuracy: 0.8750\n",
      "[Epoch 9/50] Train Loss: 0.6091, Train Accuracy: 0.6961\n",
      "[Epoch 9/50] Val Loss: 0.6385, Val Accuracy: 0.8594\n",
      "[Epoch 10/50] Train Loss: 0.6659, Train Accuracy: 0.6379\n",
      "[Epoch 10/50] Val Loss: 0.5951, Val Accuracy: 0.8594\n",
      "[Epoch 11/50] Train Loss: 0.6420, Train Accuracy: 0.6817\n",
      "[Epoch 11/50] Val Loss: 0.5426, Val Accuracy: 0.8750\n",
      "[Epoch 12/50] Train Loss: 0.6316, Train Accuracy: 0.6478\n",
      "[Epoch 12/50] Val Loss: 0.4879, Val Accuracy: 0.8906\n",
      "[Epoch 13/50] Train Loss: 0.6217, Train Accuracy: 0.6761\n",
      "[Epoch 13/50] Val Loss: 0.4423, Val Accuracy: 0.8906\n",
      "[Epoch 14/50] Train Loss: 0.6327, Train Accuracy: 0.6435\n",
      "[Epoch 14/50] Val Loss: 0.4052, Val Accuracy: 0.8750\n",
      "[Epoch 15/50] Train Loss: 0.5894, Train Accuracy: 0.6955\n",
      "[Epoch 15/50] Val Loss: 0.3868, Val Accuracy: 0.9219\n",
      "[Epoch 16/50] Train Loss: 0.5924, Train Accuracy: 0.6810\n",
      "[Epoch 16/50] Val Loss: 0.3850, Val Accuracy: 0.9219\n",
      "[Epoch 17/50] Train Loss: 0.5809, Train Accuracy: 0.7073\n",
      "[Epoch 17/50] Val Loss: 0.3905, Val Accuracy: 0.8906\n",
      "[Epoch 18/50] Train Loss: 0.5948, Train Accuracy: 0.6692\n",
      "[Epoch 18/50] Val Loss: 0.3902, Val Accuracy: 0.8281\n",
      "[Epoch 19/50] Train Loss: 0.5737, Train Accuracy: 0.7330\n",
      "[Epoch 19/50] Val Loss: 0.4016, Val Accuracy: 0.8281\n",
      "[Epoch 20/50] Train Loss: 0.5753, Train Accuracy: 0.6629\n",
      "[Epoch 20/50] Val Loss: 0.4168, Val Accuracy: 0.8594\n",
      "[Epoch 21/50] Train Loss: 0.5668, Train Accuracy: 0.7448\n",
      "[Epoch 21/50] Val Loss: 0.4552, Val Accuracy: 0.8281\n",
      "[Epoch 22/50] Train Loss: 0.4962, Train Accuracy: 0.7442\n",
      "[Epoch 22/50] Val Loss: 0.4798, Val Accuracy: 0.8281\n",
      "[Epoch 23/50] Train Loss: 0.4743, Train Accuracy: 0.7724\n",
      "[Epoch 23/50] Val Loss: 0.4632, Val Accuracy: 0.8281\n",
      "[Epoch 24/50] Train Loss: 0.4900, Train Accuracy: 0.7336\n",
      "[Epoch 24/50] Val Loss: 0.4636, Val Accuracy: 0.7656\n",
      "[Epoch 25/50] Train Loss: 0.5338, Train Accuracy: 0.7343\n",
      "[Epoch 25/50] Val Loss: 0.4657, Val Accuracy: 0.7656\n",
      "[Epoch 26/50] Train Loss: 0.5198, Train Accuracy: 0.7836\n",
      "[Epoch 26/50] Val Loss: 0.4719, Val Accuracy: 0.7656\n",
      "[Epoch 27/50] Train Loss: 0.4779, Train Accuracy: 0.7774\n",
      "[Epoch 27/50] Val Loss: 0.4683, Val Accuracy: 0.7812\n",
      "[Epoch 28/50] Train Loss: 0.4535, Train Accuracy: 0.7429\n",
      "[Epoch 28/50] Val Loss: 0.4670, Val Accuracy: 0.7812\n",
      "[Epoch 29/50] Train Loss: 0.4854, Train Accuracy: 0.7649\n",
      "[Epoch 29/50] Val Loss: 0.4261, Val Accuracy: 0.7812\n",
      "[Epoch 30/50] Train Loss: 0.4945, Train Accuracy: 0.7336\n",
      "[Epoch 30/50] Val Loss: 0.3977, Val Accuracy: 0.7969\n",
      "[Epoch 31/50] Train Loss: 0.4318, Train Accuracy: 0.8024\n",
      "[Epoch 31/50] Val Loss: 0.3638, Val Accuracy: 0.8438\n",
      "[Epoch 32/50] Train Loss: 0.4219, Train Accuracy: 0.8030\n",
      "[Epoch 32/50] Val Loss: 0.3719, Val Accuracy: 0.8281\n",
      "[Epoch 33/50] Train Loss: 0.4896, Train Accuracy: 0.7817\n",
      "[Epoch 33/50] Val Loss: 0.3677, Val Accuracy: 0.8281\n",
      "[Epoch 34/50] Train Loss: 0.4487, Train Accuracy: 0.7843\n",
      "[Epoch 34/50] Val Loss: 0.3721, Val Accuracy: 0.8281\n",
      "[Epoch 35/50] Train Loss: 0.3858, Train Accuracy: 0.8662\n",
      "[Epoch 35/50] Val Loss: 0.3655, Val Accuracy: 0.8281\n",
      "[Epoch 36/50] Train Loss: 0.4506, Train Accuracy: 0.7586\n",
      "[Epoch 36/50] Val Loss: 0.3624, Val Accuracy: 0.8281\n",
      "[Epoch 37/50] Train Loss: 0.4708, Train Accuracy: 0.7705\n",
      "[Epoch 37/50] Val Loss: 0.3570, Val Accuracy: 0.8281\n",
      "[Epoch 38/50] Train Loss: 0.4225, Train Accuracy: 0.8099\n",
      "[Epoch 38/50] Val Loss: 0.3505, Val Accuracy: 0.8438\n",
      "[Epoch 39/50] Train Loss: 0.4172, Train Accuracy: 0.7879\n",
      "[Epoch 39/50] Val Loss: 0.3730, Val Accuracy: 0.8438\n",
      "[Epoch 40/50] Train Loss: 0.3764, Train Accuracy: 0.8280\n",
      "[Epoch 40/50] Val Loss: 0.3737, Val Accuracy: 0.8438\n",
      "[Epoch 41/50] Train Loss: 0.4125, Train Accuracy: 0.8175\n",
      "[Epoch 41/50] Val Loss: 0.3786, Val Accuracy: 0.8281\n",
      "[Epoch 42/50] Train Loss: 0.4351, Train Accuracy: 0.7774\n",
      "[Epoch 42/50] Val Loss: 0.3613, Val Accuracy: 0.8438\n",
      "[Epoch 43/50] Train Loss: 0.3910, Train Accuracy: 0.8093\n",
      "[Epoch 43/50] Val Loss: 0.3486, Val Accuracy: 0.8438\n",
      "[Epoch 44/50] Train Loss: 0.4207, Train Accuracy: 0.8494\n",
      "[Epoch 44/50] Val Loss: 0.3541, Val Accuracy: 0.8438\n",
      "[Epoch 45/50] Train Loss: 0.4314, Train Accuracy: 0.8106\n",
      "[Epoch 45/50] Val Loss: 0.3449, Val Accuracy: 0.8438\n",
      "[Epoch 46/50] Train Loss: 0.3929, Train Accuracy: 0.8386\n",
      "[Epoch 46/50] Val Loss: 0.3463, Val Accuracy: 0.8438\n",
      "[Epoch 47/50] Train Loss: 0.3881, Train Accuracy: 0.8274\n",
      "[Epoch 47/50] Val Loss: 0.3419, Val Accuracy: 0.8281\n",
      "[Epoch 48/50] Train Loss: 0.3721, Train Accuracy: 0.8218\n",
      "[Epoch 48/50] Val Loss: 0.3473, Val Accuracy: 0.8281\n",
      "[Epoch 49/50] Train Loss: 0.3697, Train Accuracy: 0.8211\n",
      "[Epoch 49/50] Val Loss: 0.3637, Val Accuracy: 0.8281\n",
      "[Epoch 50/50] Train Loss: 0.4371, Train Accuracy: 0.8037\n",
      "[Epoch 50/50] Val Loss: 0.3677, Val Accuracy: 0.8281\n",
      "[BINNExplainer] Iteration 2/3...\n",
      "[Epoch 1/50] Train Loss: 0.5798, Train Accuracy: 0.6517\n",
      "[Epoch 1/50] Val Loss: 0.6928, Val Accuracy: 0.5312\n",
      "[Epoch 2/50] Train Loss: 0.5334, Train Accuracy: 0.7379\n",
      "[Epoch 2/50] Val Loss: 0.6925, Val Accuracy: 0.5312\n",
      "[Epoch 3/50] Train Loss: 0.5643, Train Accuracy: 0.7024\n",
      "[Epoch 3/50] Val Loss: 0.6918, Val Accuracy: 0.5312\n",
      "[Epoch 4/50] Train Loss: 0.5654, Train Accuracy: 0.7123\n",
      "[Epoch 4/50] Val Loss: 0.6907, Val Accuracy: 0.5312\n",
      "[Epoch 5/50] Train Loss: 0.5543, Train Accuracy: 0.6998\n",
      "[Epoch 5/50] Val Loss: 0.6879, Val Accuracy: 0.5312\n",
      "[Epoch 6/50] Train Loss: 0.5249, Train Accuracy: 0.7166\n",
      "[Epoch 6/50] Val Loss: 0.6820, Val Accuracy: 0.7031\n",
      "[Epoch 7/50] Train Loss: 0.5415, Train Accuracy: 0.7448\n",
      "[Epoch 7/50] Val Loss: 0.6696, Val Accuracy: 0.8125\n",
      "[Epoch 8/50] Train Loss: 0.5075, Train Accuracy: 0.7386\n",
      "[Epoch 8/50] Val Loss: 0.6473, Val Accuracy: 0.8906\n",
      "[Epoch 9/50] Train Loss: 0.5356, Train Accuracy: 0.7399\n",
      "[Epoch 9/50] Val Loss: 0.6134, Val Accuracy: 0.9219\n",
      "[Epoch 10/50] Train Loss: 0.5072, Train Accuracy: 0.7442\n",
      "[Epoch 10/50] Val Loss: 0.5730, Val Accuracy: 0.8281\n",
      "[Epoch 11/50] Train Loss: 0.4790, Train Accuracy: 0.7504\n",
      "[Epoch 11/50] Val Loss: 0.5338, Val Accuracy: 0.8125\n",
      "[Epoch 12/50] Train Loss: 0.4537, Train Accuracy: 0.8155\n",
      "[Epoch 12/50] Val Loss: 0.4976, Val Accuracy: 0.8594\n",
      "[Epoch 13/50] Train Loss: 0.5078, Train Accuracy: 0.7780\n",
      "[Epoch 13/50] Val Loss: 0.4644, Val Accuracy: 0.8281\n",
      "[Epoch 14/50] Train Loss: 0.4909, Train Accuracy: 0.7524\n",
      "[Epoch 14/50] Val Loss: 0.4345, Val Accuracy: 0.8438\n",
      "[Epoch 15/50] Train Loss: 0.4843, Train Accuracy: 0.7442\n",
      "[Epoch 15/50] Val Loss: 0.4086, Val Accuracy: 0.8438\n",
      "[Epoch 16/50] Train Loss: 0.4928, Train Accuracy: 0.7780\n",
      "[Epoch 16/50] Val Loss: 0.3825, Val Accuracy: 0.9062\n",
      "[Epoch 17/50] Train Loss: 0.5197, Train Accuracy: 0.7504\n",
      "[Epoch 17/50] Val Loss: 0.3719, Val Accuracy: 0.8281\n",
      "[Epoch 18/50] Train Loss: 0.4356, Train Accuracy: 0.8349\n",
      "[Epoch 18/50] Val Loss: 0.3642, Val Accuracy: 0.8281\n",
      "[Epoch 19/50] Train Loss: 0.4835, Train Accuracy: 0.8024\n",
      "[Epoch 19/50] Val Loss: 0.3563, Val Accuracy: 0.8281\n",
      "[Epoch 20/50] Train Loss: 0.4450, Train Accuracy: 0.8011\n",
      "[Epoch 20/50] Val Loss: 0.3583, Val Accuracy: 0.8125\n",
      "[Epoch 21/50] Train Loss: 0.4808, Train Accuracy: 0.7623\n",
      "[Epoch 21/50] Val Loss: 0.3529, Val Accuracy: 0.8281\n",
      "[Epoch 22/50] Train Loss: 0.4561, Train Accuracy: 0.7823\n",
      "[Epoch 22/50] Val Loss: 0.3481, Val Accuracy: 0.8281\n",
      "[Epoch 23/50] Train Loss: 0.4632, Train Accuracy: 0.7573\n",
      "[Epoch 23/50] Val Loss: 0.3566, Val Accuracy: 0.8281\n",
      "[Epoch 24/50] Train Loss: 0.4551, Train Accuracy: 0.7961\n",
      "[Epoch 24/50] Val Loss: 0.3624, Val Accuracy: 0.8125\n",
      "[Epoch 25/50] Train Loss: 0.4323, Train Accuracy: 0.8099\n",
      "[Epoch 25/50] Val Loss: 0.3710, Val Accuracy: 0.8125\n",
      "[Epoch 26/50] Train Loss: 0.4371, Train Accuracy: 0.8293\n",
      "[Epoch 26/50] Val Loss: 0.3721, Val Accuracy: 0.8125\n",
      "[Epoch 27/50] Train Loss: 0.4049, Train Accuracy: 0.8494\n",
      "[Epoch 27/50] Val Loss: 0.3789, Val Accuracy: 0.7969\n",
      "[Epoch 28/50] Train Loss: 0.4473, Train Accuracy: 0.8099\n",
      "[Epoch 28/50] Val Loss: 0.3728, Val Accuracy: 0.7969\n",
      "[Epoch 29/50] Train Loss: 0.3942, Train Accuracy: 0.8675\n",
      "[Epoch 29/50] Val Loss: 0.3823, Val Accuracy: 0.7969\n",
      "[Epoch 30/50] Train Loss: 0.4473, Train Accuracy: 0.8205\n",
      "[Epoch 30/50] Val Loss: 0.3901, Val Accuracy: 0.7969\n",
      "[Epoch 31/50] Train Loss: 0.4520, Train Accuracy: 0.7974\n",
      "[Epoch 31/50] Val Loss: 0.4039, Val Accuracy: 0.7969\n",
      "[Epoch 32/50] Train Loss: 0.3965, Train Accuracy: 0.8655\n",
      "[Epoch 32/50] Val Loss: 0.3724, Val Accuracy: 0.7969\n",
      "[Epoch 33/50] Train Loss: 0.4385, Train Accuracy: 0.7968\n",
      "[Epoch 33/50] Val Loss: 0.3614, Val Accuracy: 0.7969\n",
      "[Epoch 34/50] Train Loss: 0.4132, Train Accuracy: 0.8280\n",
      "[Epoch 34/50] Val Loss: 0.3401, Val Accuracy: 0.7969\n",
      "[Epoch 35/50] Train Loss: 0.4177, Train Accuracy: 0.8106\n",
      "[Epoch 35/50] Val Loss: 0.3308, Val Accuracy: 0.8125\n",
      "[Epoch 36/50] Train Loss: 0.4023, Train Accuracy: 0.8330\n",
      "[Epoch 36/50] Val Loss: 0.3195, Val Accuracy: 0.8281\n",
      "[Epoch 37/50] Train Loss: 0.3999, Train Accuracy: 0.8530\n",
      "[Epoch 37/50] Val Loss: 0.2933, Val Accuracy: 0.8906\n",
      "[Epoch 38/50] Train Loss: 0.3940, Train Accuracy: 0.8474\n",
      "[Epoch 38/50] Val Loss: 0.2876, Val Accuracy: 0.8750\n",
      "[Epoch 39/50] Train Loss: 0.3667, Train Accuracy: 0.8787\n",
      "[Epoch 39/50] Val Loss: 0.3063, Val Accuracy: 0.8281\n",
      "[Epoch 40/50] Train Loss: 0.3954, Train Accuracy: 0.8287\n",
      "[Epoch 40/50] Val Loss: 0.3180, Val Accuracy: 0.8281\n",
      "[Epoch 41/50] Train Loss: 0.3488, Train Accuracy: 0.8718\n",
      "[Epoch 41/50] Val Loss: 0.3122, Val Accuracy: 0.8281\n",
      "[Epoch 42/50] Train Loss: 0.3604, Train Accuracy: 0.8731\n",
      "[Epoch 42/50] Val Loss: 0.3148, Val Accuracy: 0.8438\n",
      "[Epoch 43/50] Train Loss: 0.3496, Train Accuracy: 0.8925\n",
      "[Epoch 43/50] Val Loss: 0.3225, Val Accuracy: 0.8438\n",
      "[Epoch 44/50] Train Loss: 0.3829, Train Accuracy: 0.8599\n",
      "[Epoch 44/50] Val Loss: 0.3267, Val Accuracy: 0.8438\n",
      "[Epoch 45/50] Train Loss: 0.3453, Train Accuracy: 0.8698\n",
      "[Epoch 45/50] Val Loss: 0.3373, Val Accuracy: 0.8281\n",
      "[Epoch 46/50] Train Loss: 0.3434, Train Accuracy: 0.8793\n",
      "[Epoch 46/50] Val Loss: 0.3386, Val Accuracy: 0.8281\n",
      "[Epoch 47/50] Train Loss: 0.3507, Train Accuracy: 0.8806\n",
      "[Epoch 47/50] Val Loss: 0.3299, Val Accuracy: 0.8281\n",
      "[Epoch 48/50] Train Loss: 0.2986, Train Accuracy: 0.8994\n",
      "[Epoch 48/50] Val Loss: 0.3098, Val Accuracy: 0.8438\n",
      "[Epoch 49/50] Train Loss: 0.3649, Train Accuracy: 0.8793\n",
      "[Epoch 49/50] Val Loss: 0.3033, Val Accuracy: 0.8438\n",
      "[Epoch 50/50] Train Loss: 0.3699, Train Accuracy: 0.8830\n",
      "[Epoch 50/50] Val Loss: 0.2904, Val Accuracy: 0.8594\n",
      "[BINNExplainer] Iteration 3/3...\n",
      "[Epoch 1/50] Train Loss: 0.6239, Train Accuracy: 0.6347\n",
      "[Epoch 1/50] Val Loss: 0.6930, Val Accuracy: 0.5312\n",
      "[Epoch 2/50] Train Loss: 0.5911, Train Accuracy: 0.7198\n",
      "[Epoch 2/50] Val Loss: 0.6927, Val Accuracy: 0.5312\n",
      "[Epoch 3/50] Train Loss: 0.6319, Train Accuracy: 0.6659\n",
      "[Epoch 3/50] Val Loss: 0.6922, Val Accuracy: 0.5312\n",
      "[Epoch 4/50] Train Loss: 0.5783, Train Accuracy: 0.6935\n",
      "[Epoch 4/50] Val Loss: 0.6910, Val Accuracy: 0.5312\n",
      "[Epoch 5/50] Train Loss: 0.5652, Train Accuracy: 0.6998\n",
      "[Epoch 5/50] Val Loss: 0.6885, Val Accuracy: 0.5312\n",
      "[Epoch 6/50] Train Loss: 0.5276, Train Accuracy: 0.7711\n",
      "[Epoch 6/50] Val Loss: 0.6830, Val Accuracy: 0.8125\n",
      "[Epoch 7/50] Train Loss: 0.5527, Train Accuracy: 0.7280\n",
      "[Epoch 7/50] Val Loss: 0.6716, Val Accuracy: 0.9688\n",
      "[Epoch 8/50] Train Loss: 0.5262, Train Accuracy: 0.7379\n",
      "[Epoch 8/50] Val Loss: 0.6509, Val Accuracy: 0.9531\n",
      "[Epoch 9/50] Train Loss: 0.4700, Train Accuracy: 0.8017\n",
      "[Epoch 9/50] Val Loss: 0.6198, Val Accuracy: 0.9219\n",
      "[Epoch 10/50] Train Loss: 0.4595, Train Accuracy: 0.8330\n",
      "[Epoch 10/50] Val Loss: 0.5830, Val Accuracy: 0.8906\n",
      "[Epoch 11/50] Train Loss: 0.4633, Train Accuracy: 0.8399\n",
      "[Epoch 11/50] Val Loss: 0.5437, Val Accuracy: 0.8906\n",
      "[Epoch 12/50] Train Loss: 0.4995, Train Accuracy: 0.7912\n",
      "[Epoch 12/50] Val Loss: 0.5054, Val Accuracy: 0.9062\n",
      "[Epoch 13/50] Train Loss: 0.4567, Train Accuracy: 0.8030\n",
      "[Epoch 13/50] Val Loss: 0.4730, Val Accuracy: 0.9062\n",
      "[Epoch 14/50] Train Loss: 0.4860, Train Accuracy: 0.7554\n",
      "[Epoch 14/50] Val Loss: 0.4463, Val Accuracy: 0.9375\n",
      "[Epoch 15/50] Train Loss: 0.4319, Train Accuracy: 0.8517\n",
      "[Epoch 15/50] Val Loss: 0.4240, Val Accuracy: 0.9219\n",
      "[Epoch 16/50] Train Loss: 0.4565, Train Accuracy: 0.8336\n",
      "[Epoch 16/50] Val Loss: 0.3977, Val Accuracy: 0.9219\n",
      "[Epoch 17/50] Train Loss: 0.4734, Train Accuracy: 0.7836\n",
      "[Epoch 17/50] Val Loss: 0.3732, Val Accuracy: 0.9219\n",
      "[Epoch 18/50] Train Loss: 0.4405, Train Accuracy: 0.8405\n",
      "[Epoch 18/50] Val Loss: 0.3564, Val Accuracy: 0.9219\n",
      "[Epoch 19/50] Train Loss: 0.4510, Train Accuracy: 0.8300\n",
      "[Epoch 19/50] Val Loss: 0.3336, Val Accuracy: 0.9375\n",
      "[Epoch 20/50] Train Loss: 0.4106, Train Accuracy: 0.8487\n",
      "[Epoch 20/50] Val Loss: 0.3208, Val Accuracy: 0.9375\n",
      "[Epoch 21/50] Train Loss: 0.4457, Train Accuracy: 0.8550\n",
      "[Epoch 21/50] Val Loss: 0.3022, Val Accuracy: 0.9375\n",
      "[Epoch 22/50] Train Loss: 0.4346, Train Accuracy: 0.8448\n",
      "[Epoch 22/50] Val Loss: 0.2868, Val Accuracy: 0.9375\n",
      "[Epoch 23/50] Train Loss: 0.4038, Train Accuracy: 0.8843\n",
      "[Epoch 23/50] Val Loss: 0.2727, Val Accuracy: 0.9531\n",
      "[Epoch 24/50] Train Loss: 0.3826, Train Accuracy: 0.8718\n",
      "[Epoch 24/50] Val Loss: 0.2689, Val Accuracy: 0.9375\n",
      "[Epoch 25/50] Train Loss: 0.3492, Train Accuracy: 0.8994\n",
      "[Epoch 25/50] Val Loss: 0.2664, Val Accuracy: 0.9375\n",
      "[Epoch 26/50] Train Loss: 0.3677, Train Accuracy: 0.9043\n",
      "[Epoch 26/50] Val Loss: 0.2627, Val Accuracy: 0.9375\n",
      "[Epoch 27/50] Train Loss: 0.3409, Train Accuracy: 0.8974\n",
      "[Epoch 27/50] Val Loss: 0.2592, Val Accuracy: 0.9531\n",
      "[Epoch 28/50] Train Loss: 0.3374, Train Accuracy: 0.9244\n",
      "[Epoch 28/50] Val Loss: 0.2562, Val Accuracy: 0.9531\n",
      "[Epoch 29/50] Train Loss: 0.3424, Train Accuracy: 0.8875\n",
      "[Epoch 29/50] Val Loss: 0.2508, Val Accuracy: 0.9531\n",
      "[Epoch 30/50] Train Loss: 0.3468, Train Accuracy: 0.9080\n",
      "[Epoch 30/50] Val Loss: 0.2588, Val Accuracy: 0.9375\n",
      "[Epoch 31/50] Train Loss: 0.3995, Train Accuracy: 0.8494\n",
      "[Epoch 31/50] Val Loss: 0.2593, Val Accuracy: 0.9219\n",
      "[Epoch 32/50] Train Loss: 0.3432, Train Accuracy: 0.9293\n",
      "[Epoch 32/50] Val Loss: 0.2640, Val Accuracy: 0.9219\n",
      "[Epoch 33/50] Train Loss: 0.3526, Train Accuracy: 0.9168\n",
      "[Epoch 33/50] Val Loss: 0.2698, Val Accuracy: 0.9062\n",
      "[Epoch 34/50] Train Loss: 0.3299, Train Accuracy: 0.9369\n",
      "[Epoch 34/50] Val Loss: 0.2599, Val Accuracy: 0.9219\n",
      "[Epoch 35/50] Train Loss: 0.3442, Train Accuracy: 0.9112\n",
      "[Epoch 35/50] Val Loss: 0.2607, Val Accuracy: 0.9219\n",
      "[Epoch 36/50] Train Loss: 0.3205, Train Accuracy: 0.8987\n",
      "[Epoch 36/50] Val Loss: 0.2621, Val Accuracy: 0.9219\n",
      "[Epoch 37/50] Train Loss: 0.3499, Train Accuracy: 0.8856\n",
      "[Epoch 37/50] Val Loss: 0.2683, Val Accuracy: 0.9219\n",
      "[Epoch 38/50] Train Loss: 0.3292, Train Accuracy: 0.9175\n",
      "[Epoch 38/50] Val Loss: 0.2686, Val Accuracy: 0.9062\n",
      "[Epoch 39/50] Train Loss: 0.3506, Train Accuracy: 0.9062\n",
      "[Epoch 39/50] Val Loss: 0.2614, Val Accuracy: 0.9062\n",
      "[Epoch 40/50] Train Loss: 0.3446, Train Accuracy: 0.8806\n",
      "[Epoch 40/50] Val Loss: 0.2528, Val Accuracy: 0.9375\n",
      "[Epoch 41/50] Train Loss: 0.3254, Train Accuracy: 0.9375\n",
      "[Epoch 41/50] Val Loss: 0.2535, Val Accuracy: 0.9375\n",
      "[Epoch 42/50] Train Loss: 0.3368, Train Accuracy: 0.9431\n",
      "[Epoch 42/50] Val Loss: 0.2458, Val Accuracy: 0.9375\n",
      "[Epoch 43/50] Train Loss: 0.3350, Train Accuracy: 0.9175\n",
      "[Epoch 43/50] Val Loss: 0.2412, Val Accuracy: 0.9375\n",
      "[Epoch 44/50] Train Loss: 0.3099, Train Accuracy: 0.9175\n",
      "[Epoch 44/50] Val Loss: 0.2431, Val Accuracy: 0.9375\n",
      "[Epoch 45/50] Train Loss: 0.3143, Train Accuracy: 0.8981\n",
      "[Epoch 45/50] Val Loss: 0.2389, Val Accuracy: 0.9375\n",
      "[Epoch 46/50] Train Loss: 0.3337, Train Accuracy: 0.9231\n",
      "[Epoch 46/50] Val Loss: 0.2309, Val Accuracy: 0.9375\n",
      "[Epoch 47/50] Train Loss: 0.3293, Train Accuracy: 0.8974\n",
      "[Epoch 47/50] Val Loss: 0.2230, Val Accuracy: 0.9531\n",
      "[Epoch 48/50] Train Loss: 0.3242, Train Accuracy: 0.9093\n",
      "[Epoch 48/50] Val Loss: 0.2244, Val Accuracy: 0.9375\n",
      "[Epoch 49/50] Train Loss: 0.2870, Train Accuracy: 0.9375\n",
      "[Epoch 49/50] Val Loss: 0.2219, Val Accuracy: 0.9375\n",
      "[Epoch 50/50] Train Loss: 0.3280, Train Accuracy: 0.8968\n",
      "[Epoch 50/50] Val Loss: 0.2224, Val Accuracy: 0.9375\n"
     ]
    }
   ],
   "source": [
    "average_explanations = explainer.explain(dataloaders, nr_iterations=3, num_epochs=50, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_layer</th>\n",
       "      <th>target_layer</th>\n",
       "      <th>source_node</th>\n",
       "      <th>target_node</th>\n",
       "      <th>class_idx</th>\n",
       "      <th>importance</th>\n",
       "      <th>source_id</th>\n",
       "      <th>target_id</th>\n",
       "      <th>importance_0</th>\n",
       "      <th>importance_1</th>\n",
       "      <th>importance_2</th>\n",
       "      <th>importance_mean</th>\n",
       "      <th>importance_std</th>\n",
       "      <th>normalized_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0M8Q6</td>\n",
       "      <td>R-HSA-166663</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043231</td>\n",
       "      <td>nA0M8Q6_l0</td>\n",
       "      <td>nR-HSA-166663_l1</td>\n",
       "      <td>0.023816</td>\n",
       "      <td>0.054591</td>\n",
       "      <td>0.051286</td>\n",
       "      <td>0.043231</td>\n",
       "      <td>0.013794</td>\n",
       "      <td>0.010808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0M8Q6</td>\n",
       "      <td>R-HSA-166663</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020888</td>\n",
       "      <td>nA0M8Q6_l0</td>\n",
       "      <td>nR-HSA-166663_l1</td>\n",
       "      <td>0.043425</td>\n",
       "      <td>0.013309</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>0.020888</td>\n",
       "      <td>0.016218</td>\n",
       "      <td>0.005222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0M8Q6</td>\n",
       "      <td>R-HSA-198933</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043231</td>\n",
       "      <td>nA0M8Q6_l0</td>\n",
       "      <td>nR-HSA-198933_l1</td>\n",
       "      <td>0.023816</td>\n",
       "      <td>0.054591</td>\n",
       "      <td>0.051286</td>\n",
       "      <td>0.043231</td>\n",
       "      <td>0.013794</td>\n",
       "      <td>0.010808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0M8Q6</td>\n",
       "      <td>R-HSA-198933</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020888</td>\n",
       "      <td>nA0M8Q6_l0</td>\n",
       "      <td>nR-HSA-198933_l1</td>\n",
       "      <td>0.043425</td>\n",
       "      <td>0.013309</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>0.020888</td>\n",
       "      <td>0.016218</td>\n",
       "      <td>0.005222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A0M8Q6</td>\n",
       "      <td>R-HSA-2029481</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043231</td>\n",
       "      <td>nA0M8Q6_l0</td>\n",
       "      <td>nR-HSA-2029481_l1</td>\n",
       "      <td>0.023816</td>\n",
       "      <td>0.054591</td>\n",
       "      <td>0.051286</td>\n",
       "      <td>0.043231</td>\n",
       "      <td>0.013794</td>\n",
       "      <td>0.010808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7079</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>R-HSA-9612973</td>\n",
       "      <td>output_node</td>\n",
       "      <td>1</td>\n",
       "      <td>0.089820</td>\n",
       "      <td>nR-HSA-9612973_l4</td>\n",
       "      <td>noutput_node_l5</td>\n",
       "      <td>0.108489</td>\n",
       "      <td>0.015467</td>\n",
       "      <td>0.145504</td>\n",
       "      <td>0.089820</td>\n",
       "      <td>0.054704</td>\n",
       "      <td>0.038683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7080</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>R-HSA-9709957</td>\n",
       "      <td>output_node</td>\n",
       "      <td>0</td>\n",
       "      <td>0.184374</td>\n",
       "      <td>nR-HSA-9709957_l4</td>\n",
       "      <td>noutput_node_l5</td>\n",
       "      <td>0.262943</td>\n",
       "      <td>0.206544</td>\n",
       "      <td>0.083635</td>\n",
       "      <td>0.184374</td>\n",
       "      <td>0.074862</td>\n",
       "      <td>0.092187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7081</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>R-HSA-9709957</td>\n",
       "      <td>output_node</td>\n",
       "      <td>1</td>\n",
       "      <td>0.132082</td>\n",
       "      <td>nR-HSA-9709957_l4</td>\n",
       "      <td>noutput_node_l5</td>\n",
       "      <td>0.247671</td>\n",
       "      <td>0.118751</td>\n",
       "      <td>0.029824</td>\n",
       "      <td>0.132082</td>\n",
       "      <td>0.089434</td>\n",
       "      <td>0.066041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7082</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>R-HSA-9748784</td>\n",
       "      <td>output_node</td>\n",
       "      <td>0</td>\n",
       "      <td>0.178142</td>\n",
       "      <td>nR-HSA-9748784_l4</td>\n",
       "      <td>noutput_node_l5</td>\n",
       "      <td>0.034630</td>\n",
       "      <td>0.246579</td>\n",
       "      <td>0.253217</td>\n",
       "      <td>0.178142</td>\n",
       "      <td>0.101515</td>\n",
       "      <td>0.059381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7083</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>R-HSA-9748784</td>\n",
       "      <td>output_node</td>\n",
       "      <td>1</td>\n",
       "      <td>0.140989</td>\n",
       "      <td>nR-HSA-9748784_l4</td>\n",
       "      <td>noutput_node_l5</td>\n",
       "      <td>0.227053</td>\n",
       "      <td>0.193834</td>\n",
       "      <td>0.002080</td>\n",
       "      <td>0.140989</td>\n",
       "      <td>0.099155</td>\n",
       "      <td>0.046996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7084 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      source_layer  target_layer    source_node    target_node  class_idx  \\\n",
       "0                0             1         A0M8Q6   R-HSA-166663          0   \n",
       "1                0             1         A0M8Q6   R-HSA-166663          1   \n",
       "2                0             1         A0M8Q6   R-HSA-198933          0   \n",
       "3                0             1         A0M8Q6   R-HSA-198933          1   \n",
       "4                0             1         A0M8Q6  R-HSA-2029481          0   \n",
       "...            ...           ...            ...            ...        ...   \n",
       "7079             4             5  R-HSA-9612973    output_node          1   \n",
       "7080             4             5  R-HSA-9709957    output_node          0   \n",
       "7081             4             5  R-HSA-9709957    output_node          1   \n",
       "7082             4             5  R-HSA-9748784    output_node          0   \n",
       "7083             4             5  R-HSA-9748784    output_node          1   \n",
       "\n",
       "      importance          source_id          target_id  importance_0  \\\n",
       "0       0.043231         nA0M8Q6_l0   nR-HSA-166663_l1      0.023816   \n",
       "1       0.020888         nA0M8Q6_l0   nR-HSA-166663_l1      0.043425   \n",
       "2       0.043231         nA0M8Q6_l0   nR-HSA-198933_l1      0.023816   \n",
       "3       0.020888         nA0M8Q6_l0   nR-HSA-198933_l1      0.043425   \n",
       "4       0.043231         nA0M8Q6_l0  nR-HSA-2029481_l1      0.023816   \n",
       "...          ...                ...                ...           ...   \n",
       "7079    0.089820  nR-HSA-9612973_l4    noutput_node_l5      0.108489   \n",
       "7080    0.184374  nR-HSA-9709957_l4    noutput_node_l5      0.262943   \n",
       "7081    0.132082  nR-HSA-9709957_l4    noutput_node_l5      0.247671   \n",
       "7082    0.178142  nR-HSA-9748784_l4    noutput_node_l5      0.034630   \n",
       "7083    0.140989  nR-HSA-9748784_l4    noutput_node_l5      0.227053   \n",
       "\n",
       "      importance_1  importance_2  importance_mean  importance_std  \\\n",
       "0         0.054591      0.051286         0.043231        0.013794   \n",
       "1         0.013309      0.005929         0.020888        0.016218   \n",
       "2         0.054591      0.051286         0.043231        0.013794   \n",
       "3         0.013309      0.005929         0.020888        0.016218   \n",
       "4         0.054591      0.051286         0.043231        0.013794   \n",
       "...            ...           ...              ...             ...   \n",
       "7079      0.015467      0.145504         0.089820        0.054704   \n",
       "7080      0.206544      0.083635         0.184374        0.074862   \n",
       "7081      0.118751      0.029824         0.132082        0.089434   \n",
       "7082      0.246579      0.253217         0.178142        0.101515   \n",
       "7083      0.193834      0.002080         0.140989        0.099155   \n",
       "\n",
       "      normalized_importance  \n",
       "0                  0.010808  \n",
       "1                  0.005222  \n",
       "2                  0.010808  \n",
       "3                  0.005222  \n",
       "4                  0.010808  \n",
       "...                     ...  \n",
       "7079               0.038683  \n",
       "7080               0.092187  \n",
       "7081               0.066041  \n",
       "7082               0.059381  \n",
       "7083               0.046996  \n",
       "\n",
       "[7084 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_average_explanations = explainer.normalize_importances(average_explanations, method=\"fan\")\n",
    "normalized_average_explanations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
